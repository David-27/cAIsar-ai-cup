{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54e003da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T11:52:41.940134Z",
     "start_time": "2022-06-03T11:52:36.559144Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1f9c6347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T12:18:31.216999Z",
     "start_time": "2022-06-05T12:18:31.193632Z"
    }
   },
   "outputs": [],
   "source": [
    "# gating signal (query) before upsampling from layer {i+1}{j-1}\n",
    "# skip channel @ 0\n",
    "query = tf.keras.layers.Input((32, 32))\n",
    "value = tf.keras.layers.Input((128, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce63d072",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T12:16:23.879306Z",
     "start_time": "2022-06-05T12:16:23.562554Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"additive_attention\" (type AdditiveAttention).\n\nDimensions must be equal, but are 32 and 16 for '{{node additive_attention/add}} = AddV2[T=DT_FLOAT](additive_attention/ExpandDims, additive_attention/ExpandDims_1)' with input shapes: [?,16,32,1,32], [?,16,1,128,16].\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(None, 16, 32, 32), dtype=float32)', 'tf.Tensor(shape=(None, 16, 128, 16), dtype=float32)']\n  • mask=None\n  • training=False\n  • return_attention_scores=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [90]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m attention \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdditiveAttention\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m attention\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2013\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   2010\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[0;32m   2011\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2012\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 2013\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[0;32m   2015\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c_op\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"additive_attention\" (type AdditiveAttention).\n\nDimensions must be equal, but are 32 and 16 for '{{node additive_attention/add}} = AddV2[T=DT_FLOAT](additive_attention/ExpandDims, additive_attention/ExpandDims_1)' with input shapes: [?,16,32,1,32], [?,16,1,128,16].\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(None, 16, 32, 32), dtype=float32)', 'tf.Tensor(shape=(None, 16, 128, 16), dtype=float32)']\n  • mask=None\n  • training=False\n  • return_attention_scores=False"
     ]
    }
   ],
   "source": [
    "attention = tf.keras.layers.AdditiveAttention()([query, value])\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5dc8ac03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T12:18:32.576680Z",
     "start_time": "2022-06-05T12:18:32.533950Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# require expend as and multiply and add function\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, Activation, UpSampling1D, BatchNormalization, Add, Multiply\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class AdditiveAttentionGateLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, x_res_kernel=3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # resampling kernel_size for value signal x\n",
    "        self.x_res_kernel = x_res_kernel\n",
    "    \n",
    "    def call(self, x, g, F_int, *args, **kwargs):\n",
    "        # expected shapes\n",
    "        # x -> (b, l_x, c_x)\n",
    "        # g -> (b, l_g, c_g)\n",
    "        x_shape = K.int_shape(x)\n",
    "        g_shape = K.int_shape(g)\n",
    "        \n",
    "        # reshape gating signal to F_int filters\n",
    "        # phi_g = W_g*g -> shape: (b, l_g, F_int)\n",
    "        phi_g = Conv1D(filters=F_int,\n",
    "                      kernel_size=1,\n",
    "                      strides=1,\n",
    "                      padding='same')(g)\n",
    "        phi_g = BatchNormalization()(phi_g)\n",
    "        \n",
    "        # resampling value (x) signal to shape of gating signal filters\n",
    "        # theta_x = W_x*x -> shape: (b, l_g, F_int)\n",
    "        theta_x = Conv1D(filters=F_int,\n",
    "                     kernel_size=self.x_res_kernel,\n",
    "                     strides=(x_shape[1] // g_shape[1]),\n",
    "                     padding='same')(x)\n",
    "        theta_x = BatchNormalization()(theta_x)\n",
    "        \n",
    "        sum_xg = Add()([phi_g, theta_x])\n",
    "        act_of_sum_xg = Activation('relu')(sum_xg)\n",
    "        \n",
    "        # calculate alpha as the sigmoid activation of psi * act_of_sum_xg [+ b_psi]\n",
    "        psi = Conv1D(filters=1, kernel_size=1, padding='same')(act_of_sum_xg)\n",
    "        alpha = Activation('sigmoid')(psi)\n",
    "        alpha_shape = K.int_shape(alpha)\n",
    "        \n",
    "        # upsample alpha and repeat vector along channel axis to match the shape of x\n",
    "        upsampled_alpha = UpSampling1D((x_shape[1] // alpha_shape[1]))(alpha)\n",
    "        repeated_alpha = K.repeat_elements(upsampled_alpha, x_shape[2], axis=2)\n",
    "        \n",
    "        # multiply x with attention map alpha\n",
    "        gated_x = Multiply()([x, repeated_alpha])\n",
    "        \n",
    "        return gated_x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e431a4f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T12:22:59.367329Z",
     "start_time": "2022-06-05T12:22:59.339020Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdditiveAttentionGateLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, x_res_kernel=3, **kwargs):\n",
    "        \"\"\"init method of AdditiveAttentionGateLayer\n",
    "\n",
    "        Args:\n",
    "            x_res_kernel (int, optional): Size of the x resampling kernel. Defaults to 3.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "        # resampling kernel_size for value signal x\n",
    "        self.x_res_kernel = x_res_kernel\n",
    "    \n",
    "    def call(self, x: tf.Tensor, g: tf.Tensor, F_int: int, *args, **kwargs):\n",
    "        \"\"\"call-function of the Layer\n",
    "\n",
    "        Args:\n",
    "            x (tf.Tensor): _description_\n",
    "            g (tf.Tensor): _description_\n",
    "            F_int (int): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "\n",
    "        # expected shapes\n",
    "        # x -> (b, l_x, c_x)\n",
    "        # g -> (b, l_g, c_g)\n",
    "        x_shape = K.int_shape(x)\n",
    "        g_shape = K.int_shape(g)\n",
    "        \n",
    "        # reshape gating signal to F_int filters\n",
    "        # phi_g = W_g*g -> shape: (b, l_g, F_int)\n",
    "        phi_g = Conv1D(filters=F_int,\n",
    "                      kernel_size=1,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      name='Conv1D/phi_g')(g)\n",
    "        phi_g = BatchNormalization(name='BN/phi_g')(phi_g)\n",
    "        \n",
    "        # resampling value (x) signal to shape of gating signal filters\n",
    "        # theta_x = W_x*x -> shape: (b, l_g, F_int)\n",
    "        theta_x = Conv1D(filters=F_int,\n",
    "                     kernel_size=self.x_res_kernel,\n",
    "                     strides=(x_shape[1] // g_shape[1]),\n",
    "                     padding='same',\n",
    "                     name='Conv1D/theta_x')(x)\n",
    "        theta_x = BatchNormalization(name='BN/theta_x')(theta_x)\n",
    "        \n",
    "        sum_phi_theta = Add(name='Add/sum_phi_theta')([phi_g, theta_x])\n",
    "        act_of_sum_xg = Activation('relu', name='Activation/sum_phi_theta')(sum_phi_theta)\n",
    "        \n",
    "        # calculate alpha as the sigmoid activation of psi * act_of_sum_xg [+ b_psi]\n",
    "        psi = Conv1D(filters=1, kernel_size=1, padding='same', name='Conv1D/psi')(act_of_sum_xg)\n",
    "        alpha = Activation('sigmoid', name='Activation/alpha')(psi)\n",
    "        \n",
    "        # upsample alpha -> shape: (bs, l, 1), therefore add and drop temporary \"channel\" dimension\n",
    "        # and repeat vector along channel axis to match the shape of x\n",
    "        reshaped_alpha = alpha[..., tf.newaxis]\n",
    "        upsampled_alpha = tf.image.resize(reshaped_alpha, size=(x_shape[1] , 1), method=ResizeMethod.BILINEAR)\n",
    "        repeated_alpha = K.repeat_elements(upsampled_alpha, x_shape[2], axis=2)\n",
    "        repeated_alpha = K.squeeze(repeated_alpha, axis=3)\n",
    "        \n",
    "        # multiply x with attention map alpha\n",
    "        x_gated = Multiply(name='Multiply/x_gated')([x, repeated_alpha])\n",
    "        \n",
    "        return x_gated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "40b1d911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T12:23:00.680924Z",
     "start_time": "2022-06-05T12:23:00.054423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.int_shape(x) (None, 128, 16)\n",
      "(None, 32, 1)\n",
      "K.int_shape(upsampled_alpha) (None, 128, 1, 1)\n",
      "K.int_shape(x) (None, 128, 16)\n",
      "K.int_shape(repeated_alpha) (None, 128, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128, 16) dtype=float32 (created by layer 'Fu/nny_Name')>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdditiveAttentionGateLayer(3, name='Fu/nny_Name')(value, query, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea6089",
   "metadata": {},
   "source": [
    "https://github.com/ozan-oktay/Attention-Gated-Networks/blob/master/models/layers/grid_attention_layer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2489a562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T10:30:36.038956Z",
     "start_time": "2022-06-05T10:30:30.093859Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Activation, UpSampling2D, BatchNormalization\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def AttnGatingBlock(x, g, inter_shape):\n",
    "    # https://github.com/robinvvinod/unet/blob/master/layers2D.py\n",
    "    \n",
    "    shape_x = K.int_shape(x)\n",
    "    shape_g = K.int_shape(g)\n",
    "\n",
    "    # Getting the gating signal to the same number of filters as the inter_shape\n",
    "    phi_g = Conv2D(filters=inter_shape,\n",
    "                   kernel_size=1,\n",
    "                   strides=1,\n",
    "                   padding='same')(g)\n",
    "\n",
    "    # Getting the x signal to the same shape as the gating signal\n",
    "    theta_x = Conv2D(filters=inter_shape,\n",
    "                     kernel_size=3,\n",
    "                     strides=(shape_x[1] // shape_g[1],\n",
    "                              shape_x[2] // shape_g[2]),\n",
    "                     padding='same')(x)\n",
    "\n",
    "    # Element-wise addition of the gating and x signals\n",
    "    add_xg = add([phi_g, theta_x])\n",
    "    add_xg = Activation('relu')(add_xg)\n",
    "\n",
    "    # 1x1x1 convolution\n",
    "    psi = Conv2D(filters=1, kernel_size=1, padding='same')(add_xg)\n",
    "    psi = Activation('sigmoid')(psi)\n",
    "    shape_sigmoid = K.int_shape(psi)\n",
    "\n",
    "    # Upsampling psi back to the original dimensions of x signal\n",
    "    upsample_sigmoid_xg = UpSampling2D(size=(shape_x[1] // shape_sigmoid[1],\n",
    "                                             shape_x[2] //\n",
    "                                             shape_sigmoid[2]))(psi)\n",
    "\n",
    "    # Expanding the filter axis to the number of filters in the original x signal\n",
    "    upsample_sigmoid_xg = expend_as(upsample_sigmoid_xg, shape_x[3])\n",
    "\n",
    "    # Element-wise multiplication of attention coefficients back onto original x signal\n",
    "    attn_coefficients = multiply([upsample_sigmoid_xg, x])\n",
    "\n",
    "    # Final 1x1x1 convolution to consolidate attention signal to original x dimensions\n",
    "    output = Conv2D(filters=shape_x[3],\n",
    "                    kernel_size=1,\n",
    "                    strides=1,\n",
    "                    padding='same')(attn_coefficients)\n",
    "    output = BatchNormalization()(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "316d6258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T12:27:33.330554Z",
     "start_time": "2022-06-03T12:27:33.284099Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv3D, Activation, UpSampling3D\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def AttnGatingBlock(x, g, inter_shape):\n",
    "    # https://github.com/robinvvinod/unet/blob/master/layers2D.py\n",
    "    \n",
    "    shape_x = K.int_shape(x)\n",
    "    shape_g = K.int_shape(g)\n",
    "\n",
    "    # Getting the gating signal to the same number of filters as the inter_shape\n",
    "    phi_g = Conv3D(filters=inter_shape,\n",
    "                   kernel_size=1,\n",
    "                   strides=1,\n",
    "                   padding='same')(g)\n",
    "\n",
    "    # Getting the x signal to the same shape as the gating signal\n",
    "    theta_x = Conv3D(filters=inter_shape,\n",
    "                     kernel_size=3,\n",
    "                     strides=(shape_x[1] // shape_g[1],\n",
    "                              shape_x[2] // shape_g[2],\n",
    "                              shape_x[3] // shape_g[3]),\n",
    "                     padding='same')(x)\n",
    "\n",
    "    # Element-wise addition of the gating and x signals\n",
    "    add_xg = add([phi_g, theta_x])\n",
    "    add_xg = Activation('relu')(add_xg)\n",
    "\n",
    "    # 1x1x1 convolution\n",
    "    psi = Conv3D(filters=1, kernel_size=1, padding='same')(add_xg)\n",
    "    psi = Activation('sigmoid')(psi)\n",
    "    shape_sigmoid = K.int_shape(psi)\n",
    "\n",
    "    # Upsampling psi back to the original dimensions of x signal\n",
    "    upsample_sigmoid_xg = UpSampling3D(\n",
    "        size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2],\n",
    "              shape_x[3] // shape_sigmoid[3]))(psi)\n",
    "\n",
    "    # Expanding the filter axis to the number of filters in the original x signal\n",
    "    upsample_sigmoid_xg = expend_as(upsample_sigmoid_xg, shape_x[4])\n",
    "\n",
    "    # Element-wise multiplication of attention coefficients back onto original x signal\n",
    "    attn_coefficients = multiply([upsample_sigmoid_xg, x])\n",
    "\n",
    "    # Final 1x1x1 convolution to consolidate attention signal to original x dimensions\n",
    "    output = Conv3D(filters=shape_x[4],\n",
    "                    kernel_size=1,\n",
    "                    strides=1,\n",
    "                    padding='same')(attn_coefficients)\n",
    "    output = BatchNormalization()(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18f41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable-length int sequences.\n",
    "query_input = tf.keras.Input(shape=(None,), dtype='int32')\n",
    "value_input = tf.keras.Input(shape=(None,), dtype='int32')\n",
    "\n",
    "# Embedding lookup.\n",
    "token_embedding = tf.keras.layers.Embedding(max_tokens, dimension)\n",
    "# Query embeddings of shape [batch_size, Tq, dimension].\n",
    "query_embeddings = token_embedding(query_input)\n",
    "# Value embeddings of shape [batch_size, Tv, dimension].\n",
    "value_embeddings = token_embedding(value_input)\n",
    "\n",
    "# CNN layer.\n",
    "cnn_layer = tf.keras.layers.Conv1D(\n",
    "    filters=100,\n",
    "    kernel_size=4,\n",
    "    # Use 'same' padding so outputs have the same shape as inputs.\n",
    "    padding='same')\n",
    "# Query encoding of shape [batch_size, Tq, filters].\n",
    "query_seq_encoding = cnn_layer(query_embeddings)\n",
    "# Value encoding of shape [batch_size, Tv, filters].\n",
    "value_seq_encoding = cnn_layer(value_embeddings)\n",
    "\n",
    "# Query-value attention of shape [batch_size, Tq, filters].\n",
    "query_value_attention_seq = tf.keras.layers.AdditiveAttention()(\n",
    "    [query_seq_encoding, value_seq_encoding])\n",
    "\n",
    "# Reduce over the sequence axis to produce encodings of shape\n",
    "# [batch_size, filters].\n",
    "query_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n",
    "    query_seq_encoding)\n",
    "query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n",
    "    query_value_attention_seq)\n",
    "\n",
    "# Concatenate query and document encodings to produce a DNN input layer.\n",
    "input_layer = tf.keras.layers.Concatenate()(\n",
    "    [query_encoding, query_value_attention])\n",
    "\n",
    "# Add DNN layers, and create Model.\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58389bf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T12:05:53.389856Z",
     "start_time": "2022-06-05T12:05:53.344999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 8, 1, 1), dtype=int32, numpy=\n",
       "array([[[[0]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]]],\n",
       "\n",
       "\n",
       "       [[[0]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]]],\n",
       "\n",
       "\n",
       "       [[[0]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]]],\n",
       "\n",
       "\n",
       "       [[[0]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[1]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[0]],\n",
       "\n",
       "        [[1]]]])>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.image import ResizeMethod\n",
    "\n",
    "# batch_size = 4\n",
    "# ts_length = 8\n",
    "base_line = np.array([0, 0, 1, 1, 1, 0, 0, 1])\n",
    "np_images = np.array([base_line for _ in range(4)])\n",
    "\n",
    "# add width and channel dimension\n",
    "# np_images = np_images.reshape((4,8,1,1))\n",
    "\n",
    "tf_images = tf.constant(np_images)\n",
    "tf_images = tf_images[..., tf.newaxis, tf.newaxis]\n",
    "tf_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "74be8a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-05T12:05:57.196052Z",
     "start_time": "2022-06-05T12:05:57.153103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 16, 1, 1), dtype=float32, numpy=\n",
       "array([[[[0.  ]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.25]],\n",
       "\n",
       "        [[0.75]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[0.75]],\n",
       "\n",
       "        [[0.25]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.25]],\n",
       "\n",
       "        [[0.75]],\n",
       "\n",
       "        [[1.  ]]],\n",
       "\n",
       "\n",
       "       [[[0.  ]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.25]],\n",
       "\n",
       "        [[0.75]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[0.75]],\n",
       "\n",
       "        [[0.25]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.25]],\n",
       "\n",
       "        [[0.75]],\n",
       "\n",
       "        [[1.  ]]],\n",
       "\n",
       "\n",
       "       [[[0.  ]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.25]],\n",
       "\n",
       "        [[0.75]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[0.75]],\n",
       "\n",
       "        [[0.25]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.25]],\n",
       "\n",
       "        [[0.75]],\n",
       "\n",
       "        [[1.  ]]],\n",
       "\n",
       "\n",
       "       [[[0.  ]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.25]],\n",
       "\n",
       "        [[0.75]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[1.  ]],\n",
       "\n",
       "        [[0.75]],\n",
       "\n",
       "        [[0.25]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.  ]],\n",
       "\n",
       "        [[0.25]],\n",
       "\n",
       "        [[0.75]],\n",
       "\n",
       "        [[1.  ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tf.image.resize(tf_images, size=(16,1), method=ResizeMethod.BILINEAR)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
