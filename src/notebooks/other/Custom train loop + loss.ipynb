{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d49e014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T19:18:19.389292Z",
     "start_time": "2022-06-26T19:18:12.862101Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from data_generator.batch_generator_functions import unstack_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e411fd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T16:30:10.201328Z",
     "start_time": "2022-06-26T16:29:36.329730Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-26 18:29:38.998308   [Session] Initializing ...\n",
      "2022-06-26 18:29:38.999346   [Session] Syncing existing training runs ...\n",
      "2022-06-26 18:29:39.000339   [Session] Checking for previously run epoch logs and stored weights ...\n",
      "2022-06-26 18:29:39.015615   [Session] Found log indicating no previous training (epoch: 0).\n",
      "2022-06-26 18:29:39.016624   [Session] Synced logs and weights at epoch 0.\n",
      "2022-06-26 18:29:39.016624   [Session] Finished initialization.\n",
      "2022-06-26 18:29:39.017673   [Session] Started initialize subroutine ...\n",
      "2022-06-26 18:29:39.017673   [Session] Retrieving model ...\n",
      "2022-06-26 18:29:43.503775   [Session] Retrieved model with 3448285 parameters successfully.\n",
      "2022-06-26 18:29:43.503775   [Session] Compiling model ...\n",
      "2022-06-26 18:29:43.520781   [Session] Compiled model successfully.\n",
      "2022-06-26 18:29:43.520781   [Session] Initializing data generators ...\n",
      "2022-06-26 18:29:43.521900   [UtilFunctions] Found an existing folder for C:\\Users\\ricof\\Documents\\AI-Cup 2022\\tables\\gait\\original\\by_time_series\n",
      "2022-06-26 18:29:43.522399   [UtilFunctions] Found an existing folder for C:\\Users\\ricof\\Documents\\AI-Cup 2022\\metadata\\gait\\original\\by_time_series\n",
      "2022-06-26 18:29:43.522399   [BatchGenerator] Started initialization ...\n",
      "2022-06-26 18:29:43.522399   [BatchGenerator] Selected dataset: gait_training\n",
      "2022-06-26 18:29:43.522399   [BatchGenerator] Selected normalization function: original\n",
      "2022-06-26 18:29:43.522399   [BatchGenerator] Selected normalization mode: by_time_series\n",
      "2022-06-26 18:29:43.522895   [BatchGenerator] Parsing and verifying index C:\\Users\\ricof\\Documents\\AI-Cup 2022\\data\\gait\\original\\by_time_series\\gait_training_csv_index.txt\n",
      "2022-06-26 18:29:43.631935   [BatchGenerator] Found 765 data files.\n",
      "2022-06-26 18:29:43.632942   [BatchGenerator] Found existing version of table in C:\\Users\\ricof\\Documents\\AI-Cup 2022\\tables\\gait\\original\\by_time_series\\gait_training_table.pkl\n",
      "2022-06-26 18:29:43.632942   [BatchGenerator] Found existing meta data file in C:\\Users\\ricof\\Documents\\AI-Cup 2022\\metadata\\gait\\original\\by_time_series\\gait_training_meta.json\n",
      "2022-06-26 18:29:43.637946   [BatchGenerator] Existing meta data file matches current BatchGenerator parameters.\n",
      "2022-06-26 18:29:43.683945   [BatchGenerator] Found and loaded current version of table indicating 4212 samples across 765 files in C:\\Users\\ricof\\Documents\\AI-Cup 2022\\tables\\gait\\original\\by_time_series\\gait_training_table.pkl\n",
      "2022-06-26 18:29:43.684945   [BatchGenerator] Generating batch information for shuffled batches from the data ...\n",
      "2022-06-26 18:29:43.688939   [BatchGenerator] Generated 106 batches from the data ...\n",
      "2022-06-26 18:29:43.689939   [BatchGenerator] Caching is turned ON.\n",
      "2022-06-26 18:29:43.689939   [BatchGenerator] Initializing CSV cache and pre-storing files...\n",
      "2022-06-26 18:29:58.897288   [BatchGenerator] Finished initialization of cache.\n",
      "2022-06-26 18:29:58.897288   [BatchGenerator] Finished initialization.\n",
      "2022-06-26 18:29:58.897288   [UtilFunctions] Found an existing folder for C:\\Users\\ricof\\Documents\\AI-Cup 2022\\tables\\gait\\min_max_symmetrical\\by_time_series\n",
      "2022-06-26 18:29:58.901282   [UtilFunctions] Found an existing folder for C:\\Users\\ricof\\Documents\\AI-Cup 2022\\metadata\\gait\\min_max_symmetrical\\by_time_series\n",
      "2022-06-26 18:29:58.901282   [BatchGenerator] Started initialization ...\n",
      "2022-06-26 18:29:58.901282   [BatchGenerator] Selected dataset: gait_evaluation\n",
      "2022-06-26 18:29:58.901282   [BatchGenerator] Selected normalization function: min_max_symmetrical\n",
      "2022-06-26 18:29:58.901282   [BatchGenerator] Selected normalization mode: by_time_series\n",
      "2022-06-26 18:29:58.901282   [BatchGenerator] Parsing and verifying index C:\\Users\\ricof\\Documents\\AI-Cup 2022\\data\\gait\\min_max_symmetrical\\by_time_series\\gait_evaluation_csv_index.txt\n",
      "2022-06-26 18:29:58.936376   [BatchGenerator] Found 255 data files.\n",
      "2022-06-26 18:29:58.936376   [BatchGenerator] Found existing version of table in C:\\Users\\ricof\\Documents\\AI-Cup 2022\\tables\\gait\\min_max_symmetrical\\by_time_series\\gait_evaluation_table.pkl\n",
      "2022-06-26 18:29:58.936376   [BatchGenerator] Found existing meta data file in C:\\Users\\ricof\\Documents\\AI-Cup 2022\\metadata\\gait\\min_max_symmetrical\\by_time_series\\gait_evaluation_meta.json\n",
      "2022-06-26 18:29:58.940398   [BatchGenerator] Existing meta data file matches current BatchGenerator parameters.\n",
      "2022-06-26 18:29:58.959232   [BatchGenerator] Found and loaded current version of table indicating 1270 samples across 255 files in C:\\Users\\ricof\\Documents\\AI-Cup 2022\\tables\\gait\\min_max_symmetrical\\by_time_series\\gait_evaluation_table.pkl\n",
      "2022-06-26 18:29:58.959232   [BatchGenerator] Generating batch information for  batches from the data ...\n",
      "2022-06-26 18:29:58.959232   [BatchGenerator] Generated 5 batches from the data ...\n",
      "2022-06-26 18:29:58.959232   [BatchGenerator] Caching is turned ON.\n",
      "2022-06-26 18:29:58.959232   [BatchGenerator] Initializing CSV cache and pre-storing files...\n",
      "2022-06-26 18:30:04.442250   [BatchGenerator] Finished initialization of cache.\n",
      "2022-06-26 18:30:04.442250   [BatchGenerator] Finished initialization.\n",
      "2022-06-26 18:30:04.442250   [BatchGenerator] Retrieving all data...\n",
      "2022-06-26 18:30:09.786753   [BatchGenerator] Retrieved all data.     X : (3392, 1024, 16); y : (3392, 1024, 2)\n",
      "2022-06-26 18:30:09.839451   [BatchGenerator] Retrieving all data...\n",
      "2022-06-26 18:30:10.189227   [BatchGenerator] Retrieved all data.     X : (160, 1024, 16); y : (160, 1024, 2)\n",
      "2022-06-26 18:30:10.193165   [Session] Initialized data generators.\n",
      "2022-06-26 18:30:10.193165   [Session] Finished initialize subroutine.\n"
     ]
    }
   ],
   "source": [
    "from session.cli_parser import CLIParser\n",
    "from session.session import Session\n",
    "\n",
    "cli_args = ['-id', '123406789013', \n",
    "        '-l', 'tf_cup_f1_score_loop_based', '-lp', 'beta', '0.4', \n",
    "        '-lr', '0.001', '-e', '2', '-o', 'Adam', \n",
    "        '-mc', 'UeberNet', '-mp', 'best2',\n",
    "        '-tg', 'tune_train', '-vg', 'tune_val',\n",
    "        '-svtb', 'False', '-svcp', 'False',\n",
    "        '-svhis', 'False', '-svm', 'False'\n",
    "       ]\n",
    "    \n",
    "parser = CLIParser()\n",
    "args = parser.parse_args(cli_args)\n",
    "\n",
    "session = Session(args, auto_init=False)\n",
    "session.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ad03fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T16:30:51.374163Z",
     "start_time": "2022-06-26T16:30:10.209979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start of epoch 0\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function InceptionNode.call at 0x00000298F90CAB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function InceptionNode.call at 0x00000298F8E05A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function UpsamplingLayer.call at 0x00000298F9148430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function AdditiveAttentionGate.call at 0x00000298F9148C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function UpsamplingLayer.call at 0x00000298F9580CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function AdditiveAttentionGate.call at 0x00000298F9605670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(0.0008561644, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute ResourceApplyAdam as input #9(zero-based) was expected to be a float tensor but is a double tensor [Op:ResourceApplyAdam]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(y_pred, X_tensor)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Run one step of gradient descent by updating\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# the value of the variables to minimize the loss.\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Log every 20 batches.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:671\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    668\u001b[0m   grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_gradients(grads_and_vars)\n\u001b[0;32m    669\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_gradients(grads_and_vars)\n\u001b[1;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_apply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapply_state\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\tensorflow\\python\\distribute\\merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[1;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[1;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(strategy, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribution_strategy_context\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[0;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:716\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply\u001b[1;34m(self, distribution, grads_and_vars, apply_state, name)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m distribution\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mcolocate_vars_with(var):\n\u001b[0;32m    713\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m name_scope_only_in_function_or_graph(\n\u001b[0;32m    714\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eagerly_outside_functions \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    715\u001b[0m       var\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mname):\n\u001b[1;32m--> 716\u001b[0m     update_op \u001b[38;5;241m=\u001b[39m \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39min_cross_replica_context():\n\u001b[0;32m    719\u001b[0m       \u001b[38;5;66;03m# In cross-replica context, extended.update returns a list of\u001b[39;00m\n\u001b[0;32m    720\u001b[0m       \u001b[38;5;66;03m# update ops from all replicas (group=False).\u001b[39;00m\n\u001b[0;32m    721\u001b[0m       update_ops\u001b[38;5;241m.\u001b[39mextend(update_op)\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2630\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   2627\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   2628\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2629\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2632\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[0;32m   2633\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3703\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   3700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[0;32m   3701\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[0;32m   3702\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[1;32m-> 3703\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3709\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[1;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[0;32m   3705\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[0;32m   3706\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[0;32m   3707\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[0;32m   3708\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[1;32m-> 3709\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[0;32m   3711\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    594\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:699\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var\u001b[1;34m(var, grad)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply_state\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_apply_args:\n\u001b[0;32m    698\u001b[0m   apply_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply_state\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m apply_state\n\u001b[1;32m--> 699\u001b[0m update_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_apply_dense(grad, var, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mapply_kwargs)\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var\u001b[38;5;241m.\u001b[39mconstraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    701\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies([update_op]):\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:165\u001b[0m, in \u001b[0;36mAdam._resource_apply_dense\u001b[1;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[0;32m    162\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_slot(var, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamsgrad:\n\u001b[1;32m--> 165\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResourceApplyAdam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m      \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m      \u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbeta1_power\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoefficients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbeta_1_power\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbeta2_power\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoefficients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbeta_2_power\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoefficients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr_t\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoefficients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbeta_1_t\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoefficients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbeta_2_t\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoefficients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepsilon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m      \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_locking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use_locking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m   vhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_slot(var, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvhat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py:400\u001b[0m, in \u001b[0;36mkwarg_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m    396\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    397\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{f}\u001b[39;00m\u001b[38;5;124m only takes keyword args (possible keys: \u001b[39m\u001b[38;5;132;01m{kwargs}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    398\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease pass these args as kwargs instead.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    399\u001b[0m       \u001b[38;5;241m.\u001b[39mformat(f\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mf_argspec\u001b[38;5;241m.\u001b[39margs))\n\u001b[1;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\tensorflow\\python\\ops\\gen_training_ops.py:1426\u001b[0m, in \u001b[0;36mresource_apply_adam\u001b[1;34m(var, m, v, beta1_power, beta2_power, lr, beta1, beta2, epsilon, grad, use_locking, use_nesterov, name)\u001b[0m\n\u001b[0;32m   1424\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   1425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1426\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1427\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   1428\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\.virtualenvs\\src-ga5UjBuD\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7186\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7185\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7186\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute ResourceApplyAdam as input #9(zero-based) was expected to be a float tensor but is a double tensor [Op:ResourceApplyAdam]"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/65058699/using-gradients-in-a-custom-loss-function-tensorflowkeras\n",
    "epochs = session.epochs\n",
    "\n",
    "X_unstacked = unstack_batches(session.X_train, session.batch_size)[:5, :8]\n",
    "y_unstacked = unstack_batches(session.y_train, session.batch_size)[:5, :8]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (X_batch, y_batch) in enumerate(zip(X_unstacked, y_unstacked)):\n",
    "    \n",
    "        # Open a GradientTape to record the operations run\n",
    "        # during the forward pass, which enables auto-differentiation.\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            X_tensor = tf.convert_to_tensor(X_batch, dtype=tf.float64)\n",
    "            tape.watch(X_tensor)\n",
    "            \n",
    "            # feed forwaard\n",
    "            y_pred = session.model(X_tensor, training=True)\n",
    "            \n",
    "            # Gradient and the corresponding loss function\n",
    "            loss_value = session.model.loss(y_pred, y_batch)\n",
    "            print(loss_value)\n",
    "    \n",
    "        # Use the gradient tape to automatically retrieve\n",
    "        # the gradients of the trainable variables with respect to the loss.\n",
    "        # gradients = tape.gradient(loss_value, session.model.trainable_weights)\n",
    "        gradients = tape.gradient(y_pred, X_tensor)\n",
    "        \n",
    "        # Run one step of gradient descent by updating\n",
    "        # the value of the variables to minimize the loss.\n",
    "        session.model.optimizer.apply_gradients(zip(gradients, session.model.trainable_weights))\n",
    "    \n",
    "        # Log every 20 batches.\n",
    "        if step % 1 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * session.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abb5ff1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T19:23:06.714193Z",
     "start_time": "2022-06-26T19:23:06.699013Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true * y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1 - y_true)*(1 - y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2 * p * r / (p + r + K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "776e3022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T19:23:08.055550Z",
     "start_time": "2022-06-26T19:23:08.019703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-26 21:23:08.027508   [Session] Initializing ...\n",
      "2022-06-26 21:23:08.027508   [Session] Syncing existing training runs ...\n",
      "2022-06-26 21:23:08.027508   [Session] Checking for previously run epoch logs and stored weights ...\n",
      "2022-06-26 21:23:08.035205   [Session] Found log indicating no previous training (epoch: 0).\n",
      "2022-06-26 21:23:08.035205   [Session] Created temporary checkpoint directory C:\\Users\\ricof\\Documents\\AI-Cup 2022\\models\\123406789013\\ckpts\\ ...\n",
      "2022-06-26 21:23:08.035205   [Session] Synced logs and weights at epoch 0.\n",
      "2022-06-26 21:23:08.035205   [Session] Finished initialization.\n"
     ]
    }
   ],
   "source": [
    "from session.cli_parser import CLIParser\n",
    "from session.session import Session\n",
    "\n",
    "cli_args = ['-id', '123406789013', \n",
    "        '-l', 'tf_cup_f1_score_loop_based', '-lp', 'beta', '0.4', \n",
    "        '-lr', '0.001', '-e', '2', '-o', 'Adam', \n",
    "        '-mc', 'UeberNet', '-mp', 'best2',\n",
    "        '-tg', 'tune_train', '-vg', 'tune_val',\n",
    "        '-svtb', 'False', '-svcp', 'False',\n",
    "        '-svhis', 'False', '-svm', 'False'\n",
    "       ]\n",
    "    \n",
    "parser = CLIParser()\n",
    "args = parser.parse_args(cli_args)\n",
    "\n",
    "session = Session(args, auto_init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "664de841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T19:23:10.709702Z",
     "start_time": "2022-06-26T19:23:10.689655Z"
    }
   },
   "outputs": [],
   "source": [
    "session.loss = f1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52757586",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T19:23:38.651529Z",
     "start_time": "2022-06-26T19:23:38.639178Z"
    }
   },
   "outputs": [],
   "source": [
    "session.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3247a864",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-26T19:26:36.671454Z",
     "start_time": "2022-06-26T19:23:38.653848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-26 21:23:38.656076   [Session] Starting run in current session with 2 retries left and 2 epochs remaining ...\n",
      "2022-06-26 21:23:38.656076   [Session] Started training of the model from epoch 0 for 2 epochs ...\n",
      "Epoch 1/2\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.4143 - binary_crossentropy: 18891.8672 - dice_loss: 0.3795 - accuracy: 0.5400 - auc: 0.5409 - precision: 0.5405 - recall: 0.9944 - precision_at_recall: 0.5409 - mean_absolute_error: 0.4597\n",
      "Epoch 1: saving model to C:\\Users\\ricof\\Documents\\AI-Cup 2022\\models\\123406789013\\ckpts\\cp-0001.ckpt\n",
      "106/106 [==============================] - 103s 716ms/step - loss: 0.4143 - binary_crossentropy: 18891.8672 - dice_loss: 0.3795 - accuracy: 0.5400 - auc: 0.5409 - precision: 0.5405 - recall: 0.9944 - precision_at_recall: 0.5409 - mean_absolute_error: 0.4597 - val_loss: 0.5160 - val_binary_crossentropy: 12341.0625 - val_dice_loss: 0.4657 - val_accuracy: 0.4250 - val_auc: 0.4250 - val_precision: 0.4250 - val_recall: 1.0000 - val_precision_at_recall: 0.4250 - val_mean_absolute_error: 0.5750\n",
      "Epoch 2/2\n",
      "106/106 [==============================] - ETA: 0s - loss: 0.4141 - binary_crossentropy: 86436.5547 - dice_loss: 0.3790 - accuracy: 0.5403 - auc: 0.5403 - precision: 0.5403 - recall: 0.9992 - precision_at_recall: 0.5403 - mean_absolute_error: 0.4597\n",
      "Epoch 2: saving model to C:\\Users\\ricof\\Documents\\AI-Cup 2022\\models\\123406789013\\ckpts\\cp-0002.ckpt\n",
      "106/106 [==============================] - 74s 703ms/step - loss: 0.4141 - binary_crossentropy: 86436.5547 - dice_loss: 0.3790 - accuracy: 0.5403 - auc: 0.5403 - precision: 0.5403 - recall: 0.9992 - precision_at_recall: 0.5403 - mean_absolute_error: 0.4597 - val_loss: 0.5160 - val_binary_crossentropy: 53676.5430 - val_dice_loss: 0.4657 - val_accuracy: 0.4250 - val_auc: 0.4250 - val_precision: 0.4250 - val_recall: 1.0000 - val_precision_at_recall: 0.4250 - val_mean_absolute_error: 0.5750\n",
      "2022-06-26 21:26:36.616738   [Session] Syncing existing training runs ...\n",
      "2022-06-26 21:26:36.617041   [Session] Checking for previously run epoch logs and stored weights ...\n",
      "2022-06-26 21:26:36.621567   [Session] Found log indicating previous training until epoch 2.\n",
      "2022-06-26 21:26:36.629550   [Session] Found weights from epoch 2 in C:\\Users\\ricof\\Documents\\AI-Cup 2022\\models\\123406789013\\ckpts\\cp-0002.ckpt\n",
      "2022-06-26 21:26:36.629550   [Session] Synced logs and weights at epoch 2.\n",
      "2022-06-26 21:26:36.629550   [Session] Terminating session ...\n",
      "2022-06-26 21:26:36.629550   [Session] Attempting to remove temporary directory C:\\Users\\ricof\\Documents\\AI-Cup 2022\\models\\123406789013\\ fully ...\n",
      "2022-06-26 21:26:36.655386   [Session] Removed all temporary directories.\n",
      "2022-06-26 21:26:36.655386   [Session] Terminated session.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21dacc7f1f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
