{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0def368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original tensorflow implementation\n",
    "\n",
    "  def train_step(self, data):\n",
    "    \"\"\"The logic for one training step.\n",
    "\n",
    "    This method can be overridden to support custom training logic.\n",
    "    For concrete examples of how to override this method see\n",
    "    [Customizing what happends in fit](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit).\n",
    "    This method is called by `Model.make_train_function`.\n",
    "\n",
    "    This method should contain the mathematical logic for one step of training.\n",
    "    This typically includes the forward pass, loss calculation, backpropagation,\n",
    "    and metric updates.\n",
    "\n",
    "    Configuration details for *how* this logic is run (e.g. `tf.function` and\n",
    "    `tf.distribute.Strategy` settings), should be left to\n",
    "    `Model.make_train_function`, which can also be overridden.\n",
    "\n",
    "    Args:\n",
    "      data: A nested structure of `Tensor`s.\n",
    "\n",
    "    Returns:\n",
    "      A `dict` containing values that will be passed to\n",
    "      `tf.keras.callbacks.CallbackList.on_train_batch_end`. Typically, the\n",
    "      values of the `Model`'s metrics are returned. Example:\n",
    "      `{'loss': 0.2, 'accuracy': 0.7}`.\n",
    "    \"\"\"\n",
    "    x, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n",
    "    # Run forward pass.\n",
    "    with tf.GradientTape() as tape:\n",
    "      y_pred = self(x, training=True)\n",
    "      loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
    "    self._validate_target_and_loss(y, loss)\n",
    "    # Run backwards pass.\n",
    "    self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n",
    "    return self.compute_metrics(x, y, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.engine import data_adapter\n",
    "\n",
    "def train_step(self, data):\n",
    "    X, y, sample_weight = data_adapter.unpack_x_y_sample_weight(data)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = self(x, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af0e4e",
   "metadata": {},
   "source": [
    "Below implementations adapted from https://keras.io/guides/customizing_what_happens_in_fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54e8ed4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-11T12:56:37.274086Z",
     "start_time": "2022-06-11T12:56:37.262130Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "import copy\n",
    "from tensorflow.python.eager import context\n",
    "from keras import callbacks as callbacks_module\n",
    "from keras.engine import base_layer\n",
    "from keras.engine import data_adapter\n",
    "from keras.engine import training_utils\n",
    "from keras.utils import tf_utils\n",
    "from keras.utils import traceback_utils\n",
    "from keras.utils import version_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b25654e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-11T12:49:08.985130Z",
     "start_time": "2022-06-11T12:49:08.975149Z"
    }
   },
   "outputs": [],
   "source": [
    "class BatchGenerator(Sequence):\n",
    "    def __init__(self, length, batch_size):\n",
    "        self.X = np.random.random((length, batch_size, 14))\n",
    "        self.y = np.random.random((length, batch_size, 1))\n",
    "        self.epoch_counter = 0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index, :, :], self.y[index, :, :]\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.epoch_counter += 1\n",
    "        print(f'[BG] updated self.epoch_counter: {self.epoch_counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07d52073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-11T14:41:08.638610Z",
     "start_time": "2022-06-11T14:41:08.623370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (32, 14), y: (32, 1)\n"
     ]
    }
   ],
   "source": [
    "batch_generator = BatchGenerator(20, 32)\n",
    "X, y = batch_generator.__getitem__(0)\n",
    "print(f'X: {X.shape}, y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c17516a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-11T14:41:16.518270Z",
     "start_time": "2022-06-11T14:41:15.333309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_initial_epoch': 0, '_epochs': 5, '_insufficient_data': False, '_model': <__main__.CustomModel object at 0x000001EEBCEF8100>, '_steps_per_execution': <tf.Variable 'Variable:0' shape=() dtype=int64, numpy=1>, '_adapter': <keras.engine.data_adapter.KerasSequenceAdapter object at 0x000001EEBCED1E20>, '_current_step': 0, '_step_increment': 0, '_inferred_steps': 20, '_dataset': <PrefetchDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.float32, name=None))>}\n",
      "Epoch 1/5\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "{'X': array([[[0.34819391, 0.18740289, 0.31448158, ..., 0.34214086,\n",
      "         0.30489974, 0.34475161],\n",
      "        [0.64632784, 0.40692046, 0.73995774, ..., 0.94228406,\n",
      "         0.05641092, 0.44217661],\n",
      "        [0.62172679, 0.54165388, 0.10476333, ..., 0.54237517,\n",
      "         0.93648416, 0.77627781],\n",
      "        ...,\n",
      "        [0.20314842, 0.0586868 , 0.73262245, ..., 0.8574655 ,\n",
      "         0.26323984, 0.27352727],\n",
      "        [0.98778071, 0.29886091, 0.44976843, ..., 0.44049076,\n",
      "         0.26981199, 0.83313474],\n",
      "        [0.0946683 , 0.79059126, 0.09332382, ..., 0.50608244,\n",
      "         0.00424419, 0.87698058]],\n",
      "\n",
      "       [[0.43909283, 0.09157403, 0.76764611, ..., 0.95049802,\n",
      "         0.30147817, 0.93112464],\n",
      "        [0.8444854 , 0.90210022, 0.97527922, ..., 0.66054507,\n",
      "         0.43787617, 0.44495831],\n",
      "        [0.86923154, 0.90539213, 0.85236574, ..., 0.90517941,\n",
      "         0.94208698, 0.45417341],\n",
      "        ...,\n",
      "        [0.2122088 , 0.76696047, 0.06123494, ..., 0.77294405,\n",
      "         0.79015342, 0.39083863],\n",
      "        [0.28207436, 0.09850048, 0.49777433, ..., 0.49865428,\n",
      "         0.90256424, 0.92760276],\n",
      "        [0.3435962 , 0.2954729 , 0.01500353, ..., 0.20951068,\n",
      "         0.75420967, 0.12986655]],\n",
      "\n",
      "       [[0.43304189, 0.99076121, 0.96898672, ..., 0.95282763,\n",
      "         0.81388357, 0.31636109],\n",
      "        [0.16316605, 0.29512583, 0.15944719, ..., 0.60454979,\n",
      "         0.34765158, 0.52244197],\n",
      "        [0.904045  , 0.4727175 , 0.51569142, ..., 0.08965242,\n",
      "         0.6646123 , 0.6354671 ],\n",
      "        ...,\n",
      "        [0.55777894, 0.29407059, 0.95857622, ..., 0.57544854,\n",
      "         0.15805953, 0.99590556],\n",
      "        [0.98877669, 0.54053564, 0.66332673, ..., 0.38418291,\n",
      "         0.1432721 , 0.26500975],\n",
      "        [0.70183576, 0.09387815, 0.04870487, ..., 0.05575598,\n",
      "         0.23886798, 0.94715495]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.88705326, 0.60330139, 0.27011806, ..., 0.03316472,\n",
      "         0.55259468, 0.93993123],\n",
      "        [0.69346064, 0.26785681, 0.05264299, ..., 0.69430961,\n",
      "         0.51912564, 0.99807008],\n",
      "        [0.25303996, 0.0577861 , 0.60479444, ..., 0.42311342,\n",
      "         0.98689923, 0.55030916],\n",
      "        ...,\n",
      "        [0.03498354, 0.66544869, 0.09645257, ..., 0.47661511,\n",
      "         0.89111446, 0.12489697],\n",
      "        [0.28713839, 0.49919509, 0.56303558, ..., 0.3191631 ,\n",
      "         0.93744749, 0.41137438],\n",
      "        [0.75035908, 0.56433005, 0.47438315, ..., 0.94504973,\n",
      "         0.35703231, 0.38928918]],\n",
      "\n",
      "       [[0.95629582, 0.52835387, 0.36092051, ..., 0.37275813,\n",
      "         0.96887278, 0.65880147],\n",
      "        [0.59854154, 0.59251554, 0.40133565, ..., 0.82251178,\n",
      "         0.96022337, 0.0905545 ],\n",
      "        [0.42671194, 0.7782047 , 0.68319804, ..., 0.94274524,\n",
      "         0.5102314 , 0.31443138],\n",
      "        ...,\n",
      "        [0.51765119, 0.20783865, 0.93757837, ..., 0.5067703 ,\n",
      "         0.10513741, 0.47128329],\n",
      "        [0.11377259, 0.16219828, 0.73321563, ..., 0.19418746,\n",
      "         0.76592108, 0.93257307],\n",
      "        [0.35409151, 0.88834093, 0.36697509, ..., 0.47486566,\n",
      "         0.86403047, 0.23751224]],\n",
      "\n",
      "       [[0.25660287, 0.26711699, 0.49728079, ..., 0.34074215,\n",
      "         0.65823023, 0.64975229],\n",
      "        [0.64392561, 0.95855681, 0.76080423, ..., 0.35915326,\n",
      "         0.6619132 , 0.40007374],\n",
      "        [0.44246329, 0.40647452, 0.93181449, ..., 0.40959574,\n",
      "         0.42137955, 0.04616211],\n",
      "        ...,\n",
      "        [0.4605732 , 0.8461645 , 0.61895562, ..., 0.21352901,\n",
      "         0.12275582, 0.22519439],\n",
      "        [0.18743426, 0.13098447, 0.43908907, ..., 0.80989378,\n",
      "         0.2648506 , 0.9178414 ],\n",
      "        [0.12612049, 0.65938786, 0.03981777, ..., 0.91486814,\n",
      "         0.1469071 , 0.8827035 ]]]), 'y': array([[[0.68196124],\n",
      "        [0.81613533],\n",
      "        [0.43639364],\n",
      "        [0.37048969],\n",
      "        [0.35201272],\n",
      "        [0.46032301],\n",
      "        [0.79559619],\n",
      "        [0.309492  ],\n",
      "        [0.51491779],\n",
      "        [0.17918271],\n",
      "        [0.29724696],\n",
      "        [0.8052491 ],\n",
      "        [0.22731657],\n",
      "        [0.14643739],\n",
      "        [0.11959544],\n",
      "        [0.1122813 ],\n",
      "        [0.65303455],\n",
      "        [0.13052411],\n",
      "        [0.07883758],\n",
      "        [0.56799972],\n",
      "        [0.24816022],\n",
      "        [0.97462502],\n",
      "        [0.24467552],\n",
      "        [0.7948    ],\n",
      "        [0.75042032],\n",
      "        [0.78128343],\n",
      "        [0.92306256],\n",
      "        [0.70211556],\n",
      "        [0.91795025],\n",
      "        [0.66862583],\n",
      "        [0.79924374],\n",
      "        [0.08273297]],\n",
      "\n",
      "       [[0.56106667],\n",
      "        [0.04136725],\n",
      "        [0.698472  ],\n",
      "        [0.18128929],\n",
      "        [0.21832989],\n",
      "        [0.90442808],\n",
      "        [0.86368751],\n",
      "        [0.82842179],\n",
      "        [0.69806449],\n",
      "        [0.64694692],\n",
      "        [0.11138534],\n",
      "        [0.45646143],\n",
      "        [0.275136  ],\n",
      "        [0.2384293 ],\n",
      "        [0.13576824],\n",
      "        [0.30914045],\n",
      "        [0.88438599],\n",
      "        [0.89191445],\n",
      "        [0.8365782 ],\n",
      "        [0.4808559 ],\n",
      "        [0.17308012],\n",
      "        [0.9373507 ],\n",
      "        [0.22079993],\n",
      "        [0.6139902 ],\n",
      "        [0.13175586],\n",
      "        [0.19563577],\n",
      "        [0.14673196],\n",
      "        [0.05875224],\n",
      "        [0.53759093],\n",
      "        [0.46221629],\n",
      "        [0.5620674 ],\n",
      "        [0.77753025]],\n",
      "\n",
      "       [[0.79683883],\n",
      "        [0.26421394],\n",
      "        [0.62703966],\n",
      "        [0.00204494],\n",
      "        [0.41919291],\n",
      "        [0.6147254 ],\n",
      "        [0.4064871 ],\n",
      "        [0.09034513],\n",
      "        [0.76079713],\n",
      "        [0.01454941],\n",
      "        [0.17671379],\n",
      "        [0.92870712],\n",
      "        [0.32913566],\n",
      "        [0.76282408],\n",
      "        [0.81501297],\n",
      "        [0.97744335],\n",
      "        [0.74191307],\n",
      "        [0.9888092 ],\n",
      "        [0.45951968],\n",
      "        [0.30604147],\n",
      "        [0.52816172],\n",
      "        [0.07377724],\n",
      "        [0.20231243],\n",
      "        [0.70968283],\n",
      "        [0.20708798],\n",
      "        [0.87790463],\n",
      "        [0.49016159],\n",
      "        [0.68259942],\n",
      "        [0.45228332],\n",
      "        [0.78586127],\n",
      "        [0.58020808],\n",
      "        [0.85659639]],\n",
      "\n",
      "       [[0.74353513],\n",
      "        [0.2886033 ],\n",
      "        [0.67850897],\n",
      "        [0.88631147],\n",
      "        [0.91776648],\n",
      "        [0.49141072],\n",
      "        [0.38087274],\n",
      "        [0.30387365],\n",
      "        [0.91837232],\n",
      "        [0.64964663],\n",
      "        [0.02643109],\n",
      "        [0.83621126],\n",
      "        [0.3408858 ],\n",
      "        [0.13060441],\n",
      "        [0.33846299],\n",
      "        [0.09154473],\n",
      "        [0.0227588 ],\n",
      "        [0.1987518 ],\n",
      "        [0.73667893],\n",
      "        [0.23927769],\n",
      "        [0.81345845],\n",
      "        [0.85676066],\n",
      "        [0.75684449],\n",
      "        [0.6621439 ],\n",
      "        [0.15017977],\n",
      "        [0.8248074 ],\n",
      "        [0.84704425],\n",
      "        [0.19657207],\n",
      "        [0.44856184],\n",
      "        [0.98869535],\n",
      "        [0.88710527],\n",
      "        [0.04831312]],\n",
      "\n",
      "       [[0.43967534],\n",
      "        [0.53134934],\n",
      "        [0.51233633],\n",
      "        [0.12345451],\n",
      "        [0.44216754],\n",
      "        [0.95484415],\n",
      "        [0.74604303],\n",
      "        [0.39616169],\n",
      "        [0.69588653],\n",
      "        [0.10068689],\n",
      "        [0.57977856],\n",
      "        [0.03634078],\n",
      "        [0.23498092],\n",
      "        [0.69453647],\n",
      "        [0.88002598],\n",
      "        [0.9072789 ],\n",
      "        [0.6739972 ],\n",
      "        [0.72746353],\n",
      "        [0.00530391],\n",
      "        [0.49064516],\n",
      "        [0.71216064],\n",
      "        [0.13215819],\n",
      "        [0.53826736],\n",
      "        [0.37305852],\n",
      "        [0.92854161],\n",
      "        [0.40744028],\n",
      "        [0.99539989],\n",
      "        [0.86809161],\n",
      "        [0.32128564],\n",
      "        [0.5638559 ],\n",
      "        [0.94137906],\n",
      "        [0.18620218]],\n",
      "\n",
      "       [[0.96716263],\n",
      "        [0.76071937],\n",
      "        [0.29786572],\n",
      "        [0.84405312],\n",
      "        [0.22321301],\n",
      "        [0.81747038],\n",
      "        [0.0221214 ],\n",
      "        [0.07164317],\n",
      "        [0.90575   ],\n",
      "        [0.36520745],\n",
      "        [0.10251812],\n",
      "        [0.98196665],\n",
      "        [0.11013124],\n",
      "        [0.95185558],\n",
      "        [0.00740315],\n",
      "        [0.47408093],\n",
      "        [0.54398317],\n",
      "        [0.18996193],\n",
      "        [0.41292804],\n",
      "        [0.32910098],\n",
      "        [0.27804377],\n",
      "        [0.14802532],\n",
      "        [0.42418932],\n",
      "        [0.63169727],\n",
      "        [0.39987989],\n",
      "        [0.0271106 ],\n",
      "        [0.30706778],\n",
      "        [0.73508189],\n",
      "        [0.98549894],\n",
      "        [0.1659724 ],\n",
      "        [0.22427122],\n",
      "        [0.18282927]],\n",
      "\n",
      "       [[0.67840775],\n",
      "        [0.9096251 ],\n",
      "        [0.6118039 ],\n",
      "        [0.82652595],\n",
      "        [0.16582867],\n",
      "        [0.01015371],\n",
      "        [0.98037536],\n",
      "        [0.83853287],\n",
      "        [0.23533152],\n",
      "        [0.34776973],\n",
      "        [0.80047744],\n",
      "        [0.86089855],\n",
      "        [0.72107231],\n",
      "        [0.42009143],\n",
      "        [0.52776054],\n",
      "        [0.26184484],\n",
      "        [0.72447866],\n",
      "        [0.20349504],\n",
      "        [0.84464435],\n",
      "        [0.67843857],\n",
      "        [0.06884764],\n",
      "        [0.26813975],\n",
      "        [0.80006278],\n",
      "        [0.05487967],\n",
      "        [0.1951425 ],\n",
      "        [0.78570669],\n",
      "        [0.22084974],\n",
      "        [0.42073102],\n",
      "        [0.75285833],\n",
      "        [0.81580841],\n",
      "        [0.24099118],\n",
      "        [0.0150966 ]],\n",
      "\n",
      "       [[0.39426861],\n",
      "        [0.7458892 ],\n",
      "        [0.45351029],\n",
      "        [0.00283268],\n",
      "        [0.35427194],\n",
      "        [0.92248872],\n",
      "        [0.36970356],\n",
      "        [0.22765886],\n",
      "        [0.24333159],\n",
      "        [0.66274241],\n",
      "        [0.51774098],\n",
      "        [0.80393762],\n",
      "        [0.09582582],\n",
      "        [0.93275142],\n",
      "        [0.97030256],\n",
      "        [0.24038593],\n",
      "        [0.86905869],\n",
      "        [0.761445  ],\n",
      "        [0.05997526],\n",
      "        [0.98601868],\n",
      "        [0.13694648],\n",
      "        [0.40909835],\n",
      "        [0.1128745 ],\n",
      "        [0.3482911 ],\n",
      "        [0.53546494],\n",
      "        [0.83906219],\n",
      "        [0.79170126],\n",
      "        [0.11326107],\n",
      "        [0.21099265],\n",
      "        [0.0511005 ],\n",
      "        [0.60843532],\n",
      "        [0.54268445]],\n",
      "\n",
      "       [[0.31732014],\n",
      "        [0.67277209],\n",
      "        [0.93843063],\n",
      "        [0.706322  ],\n",
      "        [0.49931148],\n",
      "        [0.14054397],\n",
      "        [0.86124443],\n",
      "        [0.06966271],\n",
      "        [0.55806849],\n",
      "        [0.52546127],\n",
      "        [0.78010928],\n",
      "        [0.32459588],\n",
      "        [0.50000426],\n",
      "        [0.16195837],\n",
      "        [0.05683568],\n",
      "        [0.30512668],\n",
      "        [0.12027135],\n",
      "        [0.15774823],\n",
      "        [0.43498261],\n",
      "        [0.77666807],\n",
      "        [0.62786526],\n",
      "        [0.57329452],\n",
      "        [0.49294019],\n",
      "        [0.8398718 ],\n",
      "        [0.1153072 ],\n",
      "        [0.2930438 ],\n",
      "        [0.55730534],\n",
      "        [0.656961  ],\n",
      "        [0.16258458],\n",
      "        [0.6821205 ],\n",
      "        [0.86369398],\n",
      "        [0.56746943]],\n",
      "\n",
      "       [[0.97250887],\n",
      "        [0.70131144],\n",
      "        [0.69268508],\n",
      "        [0.82726638],\n",
      "        [0.18552865],\n",
      "        [0.84283534],\n",
      "        [0.7207722 ],\n",
      "        [0.79121222],\n",
      "        [0.66014386],\n",
      "        [0.59391692],\n",
      "        [0.92058109],\n",
      "        [0.73969955],\n",
      "        [0.56364436],\n",
      "        [0.71286927],\n",
      "        [0.53447697],\n",
      "        [0.76911746],\n",
      "        [0.31087931],\n",
      "        [0.33102153],\n",
      "        [0.10289566],\n",
      "        [0.11978867],\n",
      "        [0.98708394],\n",
      "        [0.79311158],\n",
      "        [0.58611796],\n",
      "        [0.91116094],\n",
      "        [0.74842566],\n",
      "        [0.07433956],\n",
      "        [0.56873259],\n",
      "        [0.6312304 ],\n",
      "        [0.6551225 ],\n",
      "        [0.22963664],\n",
      "        [0.90438112],\n",
      "        [0.02352866]],\n",
      "\n",
      "       [[0.99883303],\n",
      "        [0.27830407],\n",
      "        [0.70020328],\n",
      "        [0.49686271],\n",
      "        [0.09392339],\n",
      "        [0.86639781],\n",
      "        [0.51725694],\n",
      "        [0.1413352 ],\n",
      "        [0.98468144],\n",
      "        [0.72693243],\n",
      "        [0.34455733],\n",
      "        [0.45513865],\n",
      "        [0.29606047],\n",
      "        [0.81592027],\n",
      "        [0.21170521],\n",
      "        [0.07336479],\n",
      "        [0.32449104],\n",
      "        [0.41383848],\n",
      "        [0.39957721],\n",
      "        [0.98754856],\n",
      "        [0.02106872],\n",
      "        [0.76485434],\n",
      "        [0.32750018],\n",
      "        [0.63290605],\n",
      "        [0.03828457],\n",
      "        [0.95399703],\n",
      "        [0.60742096],\n",
      "        [0.69261869],\n",
      "        [0.10717384],\n",
      "        [0.45818776],\n",
      "        [0.60628667],\n",
      "        [0.67125456]],\n",
      "\n",
      "       [[0.06250005],\n",
      "        [0.31330281],\n",
      "        [0.24616759],\n",
      "        [0.60177567],\n",
      "        [0.14769142],\n",
      "        [0.49061118],\n",
      "        [0.75823718],\n",
      "        [0.52401387],\n",
      "        [0.31067063],\n",
      "        [0.81227497],\n",
      "        [0.54711579],\n",
      "        [0.8119936 ],\n",
      "        [0.37708506],\n",
      "        [0.09208656],\n",
      "        [0.79257845],\n",
      "        [0.81205823],\n",
      "        [0.62686611],\n",
      "        [0.55768968],\n",
      "        [0.74316865],\n",
      "        [0.8895045 ],\n",
      "        [0.93563588],\n",
      "        [0.62919128],\n",
      "        [0.31364077],\n",
      "        [0.9669275 ],\n",
      "        [0.39835039],\n",
      "        [0.03081828],\n",
      "        [0.86769974],\n",
      "        [0.38756352],\n",
      "        [0.67918395],\n",
      "        [0.7218218 ],\n",
      "        [0.19300662],\n",
      "        [0.14683804]],\n",
      "\n",
      "       [[0.86320852],\n",
      "        [0.8973331 ],\n",
      "        [0.73670714],\n",
      "        [0.84935543],\n",
      "        [0.95633544],\n",
      "        [0.58453389],\n",
      "        [0.36111936],\n",
      "        [0.73479359],\n",
      "        [0.14380647],\n",
      "        [0.48619031],\n",
      "        [0.16080051],\n",
      "        [0.43306406],\n",
      "        [0.85648501],\n",
      "        [0.29420994],\n",
      "        [0.13151041],\n",
      "        [0.75715843],\n",
      "        [0.36921891],\n",
      "        [0.51317432],\n",
      "        [0.823064  ],\n",
      "        [0.21249142],\n",
      "        [0.10184143],\n",
      "        [0.61813612],\n",
      "        [0.12169939],\n",
      "        [0.05590889],\n",
      "        [0.65817527],\n",
      "        [0.00217583],\n",
      "        [0.43730831],\n",
      "        [0.3396822 ],\n",
      "        [0.88589156],\n",
      "        [0.6603234 ],\n",
      "        [0.84156947],\n",
      "        [0.66656747]],\n",
      "\n",
      "       [[0.24032674],\n",
      "        [0.43695114],\n",
      "        [0.79228727],\n",
      "        [0.28825894],\n",
      "        [0.70157259],\n",
      "        [0.47556034],\n",
      "        [0.84964748],\n",
      "        [0.17282311],\n",
      "        [0.14629587],\n",
      "        [0.91912081],\n",
      "        [0.42609606],\n",
      "        [0.68547068],\n",
      "        [0.10378526],\n",
      "        [0.76323926],\n",
      "        [0.18776732],\n",
      "        [0.66517507],\n",
      "        [0.32922433],\n",
      "        [0.67885316],\n",
      "        [0.96696984],\n",
      "        [0.01766892],\n",
      "        [0.53180295],\n",
      "        [0.21028627],\n",
      "        [0.08409837],\n",
      "        [0.47714933],\n",
      "        [0.87772393],\n",
      "        [0.4434407 ],\n",
      "        [0.36457062],\n",
      "        [0.6961336 ],\n",
      "        [0.55752443],\n",
      "        [0.91172177],\n",
      "        [0.34757206],\n",
      "        [0.43184198]],\n",
      "\n",
      "       [[0.7718958 ],\n",
      "        [0.8718299 ],\n",
      "        [0.51963474],\n",
      "        [0.23776447],\n",
      "        [0.35274097],\n",
      "        [0.04496065],\n",
      "        [0.48995815],\n",
      "        [0.19195742],\n",
      "        [0.58761515],\n",
      "        [0.27019664],\n",
      "        [0.3101439 ],\n",
      "        [0.55191748],\n",
      "        [0.68986307],\n",
      "        [0.63354182],\n",
      "        [0.75023096],\n",
      "        [0.45015188],\n",
      "        [0.17576925],\n",
      "        [0.23385343],\n",
      "        [0.46080105],\n",
      "        [0.84642493],\n",
      "        [0.99445724],\n",
      "        [0.25935999],\n",
      "        [0.30168399],\n",
      "        [0.91673555],\n",
      "        [0.9359693 ],\n",
      "        [0.55139665],\n",
      "        [0.00550544],\n",
      "        [0.0344661 ],\n",
      "        [0.97106545],\n",
      "        [0.3056664 ],\n",
      "        [0.50795084],\n",
      "        [0.46729232]],\n",
      "\n",
      "       [[0.44165913],\n",
      "        [0.70820406],\n",
      "        [0.33101429],\n",
      "        [0.68529404],\n",
      "        [0.78494655],\n",
      "        [0.62321944],\n",
      "        [0.22278574],\n",
      "        [0.62700871],\n",
      "        [0.01674255],\n",
      "        [0.26192345],\n",
      "        [0.5990458 ],\n",
      "        [0.93592634],\n",
      "        [0.27425754],\n",
      "        [0.6945223 ],\n",
      "        [0.69021575],\n",
      "        [0.71704491],\n",
      "        [0.92619001],\n",
      "        [0.31409164],\n",
      "        [0.52476534],\n",
      "        [0.13178551],\n",
      "        [0.21838897],\n",
      "        [0.59891429],\n",
      "        [0.51659739],\n",
      "        [0.93862595],\n",
      "        [0.63512566],\n",
      "        [0.41760071],\n",
      "        [0.70548967],\n",
      "        [0.9730768 ],\n",
      "        [0.88259117],\n",
      "        [0.95044927],\n",
      "        [0.70944005],\n",
      "        [0.26381837]],\n",
      "\n",
      "       [[0.68675893],\n",
      "        [0.55681391],\n",
      "        [0.6259185 ],\n",
      "        [0.65227739],\n",
      "        [0.51025619],\n",
      "        [0.89580788],\n",
      "        [0.05576177],\n",
      "        [0.97614958],\n",
      "        [0.02965864],\n",
      "        [0.51961077],\n",
      "        [0.05512912],\n",
      "        [0.27529161],\n",
      "        [0.74743244],\n",
      "        [0.21317024],\n",
      "        [0.72622531],\n",
      "        [0.85518425],\n",
      "        [0.43267533],\n",
      "        [0.77941548],\n",
      "        [0.64310295],\n",
      "        [0.9735165 ],\n",
      "        [0.44812213],\n",
      "        [0.51285389],\n",
      "        [0.09764763],\n",
      "        [0.55672793],\n",
      "        [0.41846938],\n",
      "        [0.82765004],\n",
      "        [0.96591333],\n",
      "        [0.07438332],\n",
      "        [0.54639297],\n",
      "        [0.18573948],\n",
      "        [0.16569813],\n",
      "        [0.15000523]],\n",
      "\n",
      "       [[0.16478202],\n",
      "        [0.16439384],\n",
      "        [0.57981662],\n",
      "        [0.27846354],\n",
      "        [0.75646745],\n",
      "        [0.96746262],\n",
      "        [0.36069683],\n",
      "        [0.02813042],\n",
      "        [0.29219402],\n",
      "        [0.94883475],\n",
      "        [0.81116623],\n",
      "        [0.00871009],\n",
      "        [0.05951741],\n",
      "        [0.03647283],\n",
      "        [0.73804131],\n",
      "        [0.83311935],\n",
      "        [0.9514004 ],\n",
      "        [0.22668437],\n",
      "        [0.3012742 ],\n",
      "        [0.60912721],\n",
      "        [0.17479307],\n",
      "        [0.48053689],\n",
      "        [0.03770247],\n",
      "        [0.83994447],\n",
      "        [0.51709736],\n",
      "        [0.11817616],\n",
      "        [0.19021804],\n",
      "        [0.16613644],\n",
      "        [0.18864742],\n",
      "        [0.63107913],\n",
      "        [0.32729687],\n",
      "        [0.94508503]],\n",
      "\n",
      "       [[0.45247742],\n",
      "        [0.52967779],\n",
      "        [0.78242471],\n",
      "        [0.32519738],\n",
      "        [0.53774545],\n",
      "        [0.67016981],\n",
      "        [0.92872104],\n",
      "        [0.50157329],\n",
      "        [0.54048988],\n",
      "        [0.52587107],\n",
      "        [0.29157083],\n",
      "        [0.13780819],\n",
      "        [0.99260397],\n",
      "        [0.26641335],\n",
      "        [0.72633542],\n",
      "        [0.34300959],\n",
      "        [0.00801982],\n",
      "        [0.24280761],\n",
      "        [0.46921471],\n",
      "        [0.55112368],\n",
      "        [0.75365503],\n",
      "        [0.70606357],\n",
      "        [0.88327498],\n",
      "        [0.17474652],\n",
      "        [0.8105596 ],\n",
      "        [0.88910555],\n",
      "        [0.11354102],\n",
      "        [0.75036111],\n",
      "        [0.79873197],\n",
      "        [0.36990048],\n",
      "        [0.31389791],\n",
      "        [0.06899799]],\n",
      "\n",
      "       [[0.94149773],\n",
      "        [0.9045997 ],\n",
      "        [0.68196385],\n",
      "        [0.88243726],\n",
      "        [0.73622134],\n",
      "        [0.0448414 ],\n",
      "        [0.56008793],\n",
      "        [0.01917757],\n",
      "        [0.05043661],\n",
      "        [0.494574  ],\n",
      "        [0.62048265],\n",
      "        [0.22224793],\n",
      "        [0.7379109 ],\n",
      "        [0.55396902],\n",
      "        [0.82708081],\n",
      "        [0.809873  ],\n",
      "        [0.31703615],\n",
      "        [0.70885932],\n",
      "        [0.03374566],\n",
      "        [0.59737358],\n",
      "        [0.35530368],\n",
      "        [0.16273401],\n",
      "        [0.8118951 ],\n",
      "        [0.19701725],\n",
      "        [0.25659418],\n",
      "        [0.92189054],\n",
      "        [0.83499693],\n",
      "        [0.10067763],\n",
      "        [0.25765212],\n",
      "        [0.83608937],\n",
      "        [0.33131239],\n",
      "        [0.08591809]]]), 'epoch_counter': 0}\n",
      "data: <class 'tuple'>, X: <class 'tensorflow.python.framework.ops.Tensor'> (None, None), y: <class 'tensorflow.python.framework.ops.Tensor'> (None, None)\n",
      "{'X': array([[[0.34819391, 0.18740289, 0.31448158, ..., 0.34214086,\n",
      "         0.30489974, 0.34475161],\n",
      "        [0.64632784, 0.40692046, 0.73995774, ..., 0.94228406,\n",
      "         0.05641092, 0.44217661],\n",
      "        [0.62172679, 0.54165388, 0.10476333, ..., 0.54237517,\n",
      "         0.93648416, 0.77627781],\n",
      "        ...,\n",
      "        [0.20314842, 0.0586868 , 0.73262245, ..., 0.8574655 ,\n",
      "         0.26323984, 0.27352727],\n",
      "        [0.98778071, 0.29886091, 0.44976843, ..., 0.44049076,\n",
      "         0.26981199, 0.83313474],\n",
      "        [0.0946683 , 0.79059126, 0.09332382, ..., 0.50608244,\n",
      "         0.00424419, 0.87698058]],\n",
      "\n",
      "       [[0.43909283, 0.09157403, 0.76764611, ..., 0.95049802,\n",
      "         0.30147817, 0.93112464],\n",
      "        [0.8444854 , 0.90210022, 0.97527922, ..., 0.66054507,\n",
      "         0.43787617, 0.44495831],\n",
      "        [0.86923154, 0.90539213, 0.85236574, ..., 0.90517941,\n",
      "         0.94208698, 0.45417341],\n",
      "        ...,\n",
      "        [0.2122088 , 0.76696047, 0.06123494, ..., 0.77294405,\n",
      "         0.79015342, 0.39083863],\n",
      "        [0.28207436, 0.09850048, 0.49777433, ..., 0.49865428,\n",
      "         0.90256424, 0.92760276],\n",
      "        [0.3435962 , 0.2954729 , 0.01500353, ..., 0.20951068,\n",
      "         0.75420967, 0.12986655]],\n",
      "\n",
      "       [[0.43304189, 0.99076121, 0.96898672, ..., 0.95282763,\n",
      "         0.81388357, 0.31636109],\n",
      "        [0.16316605, 0.29512583, 0.15944719, ..., 0.60454979,\n",
      "         0.34765158, 0.52244197],\n",
      "        [0.904045  , 0.4727175 , 0.51569142, ..., 0.08965242,\n",
      "         0.6646123 , 0.6354671 ],\n",
      "        ...,\n",
      "        [0.55777894, 0.29407059, 0.95857622, ..., 0.57544854,\n",
      "         0.15805953, 0.99590556],\n",
      "        [0.98877669, 0.54053564, 0.66332673, ..., 0.38418291,\n",
      "         0.1432721 , 0.26500975],\n",
      "        [0.70183576, 0.09387815, 0.04870487, ..., 0.05575598,\n",
      "         0.23886798, 0.94715495]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.88705326, 0.60330139, 0.27011806, ..., 0.03316472,\n",
      "         0.55259468, 0.93993123],\n",
      "        [0.69346064, 0.26785681, 0.05264299, ..., 0.69430961,\n",
      "         0.51912564, 0.99807008],\n",
      "        [0.25303996, 0.0577861 , 0.60479444, ..., 0.42311342,\n",
      "         0.98689923, 0.55030916],\n",
      "        ...,\n",
      "        [0.03498354, 0.66544869, 0.09645257, ..., 0.47661511,\n",
      "         0.89111446, 0.12489697],\n",
      "        [0.28713839, 0.49919509, 0.56303558, ..., 0.3191631 ,\n",
      "         0.93744749, 0.41137438],\n",
      "        [0.75035908, 0.56433005, 0.47438315, ..., 0.94504973,\n",
      "         0.35703231, 0.38928918]],\n",
      "\n",
      "       [[0.95629582, 0.52835387, 0.36092051, ..., 0.37275813,\n",
      "         0.96887278, 0.65880147],\n",
      "        [0.59854154, 0.59251554, 0.40133565, ..., 0.82251178,\n",
      "         0.96022337, 0.0905545 ],\n",
      "        [0.42671194, 0.7782047 , 0.68319804, ..., 0.94274524,\n",
      "         0.5102314 , 0.31443138],\n",
      "        ...,\n",
      "        [0.51765119, 0.20783865, 0.93757837, ..., 0.5067703 ,\n",
      "         0.10513741, 0.47128329],\n",
      "        [0.11377259, 0.16219828, 0.73321563, ..., 0.19418746,\n",
      "         0.76592108, 0.93257307],\n",
      "        [0.35409151, 0.88834093, 0.36697509, ..., 0.47486566,\n",
      "         0.86403047, 0.23751224]],\n",
      "\n",
      "       [[0.25660287, 0.26711699, 0.49728079, ..., 0.34074215,\n",
      "         0.65823023, 0.64975229],\n",
      "        [0.64392561, 0.95855681, 0.76080423, ..., 0.35915326,\n",
      "         0.6619132 , 0.40007374],\n",
      "        [0.44246329, 0.40647452, 0.93181449, ..., 0.40959574,\n",
      "         0.42137955, 0.04616211],\n",
      "        ...,\n",
      "        [0.4605732 , 0.8461645 , 0.61895562, ..., 0.21352901,\n",
      "         0.12275582, 0.22519439],\n",
      "        [0.18743426, 0.13098447, 0.43908907, ..., 0.80989378,\n",
      "         0.2648506 , 0.9178414 ],\n",
      "        [0.12612049, 0.65938786, 0.03981777, ..., 0.91486814,\n",
      "         0.1469071 , 0.8827035 ]]]), 'y': array([[[0.68196124],\n",
      "        [0.81613533],\n",
      "        [0.43639364],\n",
      "        [0.37048969],\n",
      "        [0.35201272],\n",
      "        [0.46032301],\n",
      "        [0.79559619],\n",
      "        [0.309492  ],\n",
      "        [0.51491779],\n",
      "        [0.17918271],\n",
      "        [0.29724696],\n",
      "        [0.8052491 ],\n",
      "        [0.22731657],\n",
      "        [0.14643739],\n",
      "        [0.11959544],\n",
      "        [0.1122813 ],\n",
      "        [0.65303455],\n",
      "        [0.13052411],\n",
      "        [0.07883758],\n",
      "        [0.56799972],\n",
      "        [0.24816022],\n",
      "        [0.97462502],\n",
      "        [0.24467552],\n",
      "        [0.7948    ],\n",
      "        [0.75042032],\n",
      "        [0.78128343],\n",
      "        [0.92306256],\n",
      "        [0.70211556],\n",
      "        [0.91795025],\n",
      "        [0.66862583],\n",
      "        [0.79924374],\n",
      "        [0.08273297]],\n",
      "\n",
      "       [[0.56106667],\n",
      "        [0.04136725],\n",
      "        [0.698472  ],\n",
      "        [0.18128929],\n",
      "        [0.21832989],\n",
      "        [0.90442808],\n",
      "        [0.86368751],\n",
      "        [0.82842179],\n",
      "        [0.69806449],\n",
      "        [0.64694692],\n",
      "        [0.11138534],\n",
      "        [0.45646143],\n",
      "        [0.275136  ],\n",
      "        [0.2384293 ],\n",
      "        [0.13576824],\n",
      "        [0.30914045],\n",
      "        [0.88438599],\n",
      "        [0.89191445],\n",
      "        [0.8365782 ],\n",
      "        [0.4808559 ],\n",
      "        [0.17308012],\n",
      "        [0.9373507 ],\n",
      "        [0.22079993],\n",
      "        [0.6139902 ],\n",
      "        [0.13175586],\n",
      "        [0.19563577],\n",
      "        [0.14673196],\n",
      "        [0.05875224],\n",
      "        [0.53759093],\n",
      "        [0.46221629],\n",
      "        [0.5620674 ],\n",
      "        [0.77753025]],\n",
      "\n",
      "       [[0.79683883],\n",
      "        [0.26421394],\n",
      "        [0.62703966],\n",
      "        [0.00204494],\n",
      "        [0.41919291],\n",
      "        [0.6147254 ],\n",
      "        [0.4064871 ],\n",
      "        [0.09034513],\n",
      "        [0.76079713],\n",
      "        [0.01454941],\n",
      "        [0.17671379],\n",
      "        [0.92870712],\n",
      "        [0.32913566],\n",
      "        [0.76282408],\n",
      "        [0.81501297],\n",
      "        [0.97744335],\n",
      "        [0.74191307],\n",
      "        [0.9888092 ],\n",
      "        [0.45951968],\n",
      "        [0.30604147],\n",
      "        [0.52816172],\n",
      "        [0.07377724],\n",
      "        [0.20231243],\n",
      "        [0.70968283],\n",
      "        [0.20708798],\n",
      "        [0.87790463],\n",
      "        [0.49016159],\n",
      "        [0.68259942],\n",
      "        [0.45228332],\n",
      "        [0.78586127],\n",
      "        [0.58020808],\n",
      "        [0.85659639]],\n",
      "\n",
      "       [[0.74353513],\n",
      "        [0.2886033 ],\n",
      "        [0.67850897],\n",
      "        [0.88631147],\n",
      "        [0.91776648],\n",
      "        [0.49141072],\n",
      "        [0.38087274],\n",
      "        [0.30387365],\n",
      "        [0.91837232],\n",
      "        [0.64964663],\n",
      "        [0.02643109],\n",
      "        [0.83621126],\n",
      "        [0.3408858 ],\n",
      "        [0.13060441],\n",
      "        [0.33846299],\n",
      "        [0.09154473],\n",
      "        [0.0227588 ],\n",
      "        [0.1987518 ],\n",
      "        [0.73667893],\n",
      "        [0.23927769],\n",
      "        [0.81345845],\n",
      "        [0.85676066],\n",
      "        [0.75684449],\n",
      "        [0.6621439 ],\n",
      "        [0.15017977],\n",
      "        [0.8248074 ],\n",
      "        [0.84704425],\n",
      "        [0.19657207],\n",
      "        [0.44856184],\n",
      "        [0.98869535],\n",
      "        [0.88710527],\n",
      "        [0.04831312]],\n",
      "\n",
      "       [[0.43967534],\n",
      "        [0.53134934],\n",
      "        [0.51233633],\n",
      "        [0.12345451],\n",
      "        [0.44216754],\n",
      "        [0.95484415],\n",
      "        [0.74604303],\n",
      "        [0.39616169],\n",
      "        [0.69588653],\n",
      "        [0.10068689],\n",
      "        [0.57977856],\n",
      "        [0.03634078],\n",
      "        [0.23498092],\n",
      "        [0.69453647],\n",
      "        [0.88002598],\n",
      "        [0.9072789 ],\n",
      "        [0.6739972 ],\n",
      "        [0.72746353],\n",
      "        [0.00530391],\n",
      "        [0.49064516],\n",
      "        [0.71216064],\n",
      "        [0.13215819],\n",
      "        [0.53826736],\n",
      "        [0.37305852],\n",
      "        [0.92854161],\n",
      "        [0.40744028],\n",
      "        [0.99539989],\n",
      "        [0.86809161],\n",
      "        [0.32128564],\n",
      "        [0.5638559 ],\n",
      "        [0.94137906],\n",
      "        [0.18620218]],\n",
      "\n",
      "       [[0.96716263],\n",
      "        [0.76071937],\n",
      "        [0.29786572],\n",
      "        [0.84405312],\n",
      "        [0.22321301],\n",
      "        [0.81747038],\n",
      "        [0.0221214 ],\n",
      "        [0.07164317],\n",
      "        [0.90575   ],\n",
      "        [0.36520745],\n",
      "        [0.10251812],\n",
      "        [0.98196665],\n",
      "        [0.11013124],\n",
      "        [0.95185558],\n",
      "        [0.00740315],\n",
      "        [0.47408093],\n",
      "        [0.54398317],\n",
      "        [0.18996193],\n",
      "        [0.41292804],\n",
      "        [0.32910098],\n",
      "        [0.27804377],\n",
      "        [0.14802532],\n",
      "        [0.42418932],\n",
      "        [0.63169727],\n",
      "        [0.39987989],\n",
      "        [0.0271106 ],\n",
      "        [0.30706778],\n",
      "        [0.73508189],\n",
      "        [0.98549894],\n",
      "        [0.1659724 ],\n",
      "        [0.22427122],\n",
      "        [0.18282927]],\n",
      "\n",
      "       [[0.67840775],\n",
      "        [0.9096251 ],\n",
      "        [0.6118039 ],\n",
      "        [0.82652595],\n",
      "        [0.16582867],\n",
      "        [0.01015371],\n",
      "        [0.98037536],\n",
      "        [0.83853287],\n",
      "        [0.23533152],\n",
      "        [0.34776973],\n",
      "        [0.80047744],\n",
      "        [0.86089855],\n",
      "        [0.72107231],\n",
      "        [0.42009143],\n",
      "        [0.52776054],\n",
      "        [0.26184484],\n",
      "        [0.72447866],\n",
      "        [0.20349504],\n",
      "        [0.84464435],\n",
      "        [0.67843857],\n",
      "        [0.06884764],\n",
      "        [0.26813975],\n",
      "        [0.80006278],\n",
      "        [0.05487967],\n",
      "        [0.1951425 ],\n",
      "        [0.78570669],\n",
      "        [0.22084974],\n",
      "        [0.42073102],\n",
      "        [0.75285833],\n",
      "        [0.81580841],\n",
      "        [0.24099118],\n",
      "        [0.0150966 ]],\n",
      "\n",
      "       [[0.39426861],\n",
      "        [0.7458892 ],\n",
      "        [0.45351029],\n",
      "        [0.00283268],\n",
      "        [0.35427194],\n",
      "        [0.92248872],\n",
      "        [0.36970356],\n",
      "        [0.22765886],\n",
      "        [0.24333159],\n",
      "        [0.66274241],\n",
      "        [0.51774098],\n",
      "        [0.80393762],\n",
      "        [0.09582582],\n",
      "        [0.93275142],\n",
      "        [0.97030256],\n",
      "        [0.24038593],\n",
      "        [0.86905869],\n",
      "        [0.761445  ],\n",
      "        [0.05997526],\n",
      "        [0.98601868],\n",
      "        [0.13694648],\n",
      "        [0.40909835],\n",
      "        [0.1128745 ],\n",
      "        [0.3482911 ],\n",
      "        [0.53546494],\n",
      "        [0.83906219],\n",
      "        [0.79170126],\n",
      "        [0.11326107],\n",
      "        [0.21099265],\n",
      "        [0.0511005 ],\n",
      "        [0.60843532],\n",
      "        [0.54268445]],\n",
      "\n",
      "       [[0.31732014],\n",
      "        [0.67277209],\n",
      "        [0.93843063],\n",
      "        [0.706322  ],\n",
      "        [0.49931148],\n",
      "        [0.14054397],\n",
      "        [0.86124443],\n",
      "        [0.06966271],\n",
      "        [0.55806849],\n",
      "        [0.52546127],\n",
      "        [0.78010928],\n",
      "        [0.32459588],\n",
      "        [0.50000426],\n",
      "        [0.16195837],\n",
      "        [0.05683568],\n",
      "        [0.30512668],\n",
      "        [0.12027135],\n",
      "        [0.15774823],\n",
      "        [0.43498261],\n",
      "        [0.77666807],\n",
      "        [0.62786526],\n",
      "        [0.57329452],\n",
      "        [0.49294019],\n",
      "        [0.8398718 ],\n",
      "        [0.1153072 ],\n",
      "        [0.2930438 ],\n",
      "        [0.55730534],\n",
      "        [0.656961  ],\n",
      "        [0.16258458],\n",
      "        [0.6821205 ],\n",
      "        [0.86369398],\n",
      "        [0.56746943]],\n",
      "\n",
      "       [[0.97250887],\n",
      "        [0.70131144],\n",
      "        [0.69268508],\n",
      "        [0.82726638],\n",
      "        [0.18552865],\n",
      "        [0.84283534],\n",
      "        [0.7207722 ],\n",
      "        [0.79121222],\n",
      "        [0.66014386],\n",
      "        [0.59391692],\n",
      "        [0.92058109],\n",
      "        [0.73969955],\n",
      "        [0.56364436],\n",
      "        [0.71286927],\n",
      "        [0.53447697],\n",
      "        [0.76911746],\n",
      "        [0.31087931],\n",
      "        [0.33102153],\n",
      "        [0.10289566],\n",
      "        [0.11978867],\n",
      "        [0.98708394],\n",
      "        [0.79311158],\n",
      "        [0.58611796],\n",
      "        [0.91116094],\n",
      "        [0.74842566],\n",
      "        [0.07433956],\n",
      "        [0.56873259],\n",
      "        [0.6312304 ],\n",
      "        [0.6551225 ],\n",
      "        [0.22963664],\n",
      "        [0.90438112],\n",
      "        [0.02352866]],\n",
      "\n",
      "       [[0.99883303],\n",
      "        [0.27830407],\n",
      "        [0.70020328],\n",
      "        [0.49686271],\n",
      "        [0.09392339],\n",
      "        [0.86639781],\n",
      "        [0.51725694],\n",
      "        [0.1413352 ],\n",
      "        [0.98468144],\n",
      "        [0.72693243],\n",
      "        [0.34455733],\n",
      "        [0.45513865],\n",
      "        [0.29606047],\n",
      "        [0.81592027],\n",
      "        [0.21170521],\n",
      "        [0.07336479],\n",
      "        [0.32449104],\n",
      "        [0.41383848],\n",
      "        [0.39957721],\n",
      "        [0.98754856],\n",
      "        [0.02106872],\n",
      "        [0.76485434],\n",
      "        [0.32750018],\n",
      "        [0.63290605],\n",
      "        [0.03828457],\n",
      "        [0.95399703],\n",
      "        [0.60742096],\n",
      "        [0.69261869],\n",
      "        [0.10717384],\n",
      "        [0.45818776],\n",
      "        [0.60628667],\n",
      "        [0.67125456]],\n",
      "\n",
      "       [[0.06250005],\n",
      "        [0.31330281],\n",
      "        [0.24616759],\n",
      "        [0.60177567],\n",
      "        [0.14769142],\n",
      "        [0.49061118],\n",
      "        [0.75823718],\n",
      "        [0.52401387],\n",
      "        [0.31067063],\n",
      "        [0.81227497],\n",
      "        [0.54711579],\n",
      "        [0.8119936 ],\n",
      "        [0.37708506],\n",
      "        [0.09208656],\n",
      "        [0.79257845],\n",
      "        [0.81205823],\n",
      "        [0.62686611],\n",
      "        [0.55768968],\n",
      "        [0.74316865],\n",
      "        [0.8895045 ],\n",
      "        [0.93563588],\n",
      "        [0.62919128],\n",
      "        [0.31364077],\n",
      "        [0.9669275 ],\n",
      "        [0.39835039],\n",
      "        [0.03081828],\n",
      "        [0.86769974],\n",
      "        [0.38756352],\n",
      "        [0.67918395],\n",
      "        [0.7218218 ],\n",
      "        [0.19300662],\n",
      "        [0.14683804]],\n",
      "\n",
      "       [[0.86320852],\n",
      "        [0.8973331 ],\n",
      "        [0.73670714],\n",
      "        [0.84935543],\n",
      "        [0.95633544],\n",
      "        [0.58453389],\n",
      "        [0.36111936],\n",
      "        [0.73479359],\n",
      "        [0.14380647],\n",
      "        [0.48619031],\n",
      "        [0.16080051],\n",
      "        [0.43306406],\n",
      "        [0.85648501],\n",
      "        [0.29420994],\n",
      "        [0.13151041],\n",
      "        [0.75715843],\n",
      "        [0.36921891],\n",
      "        [0.51317432],\n",
      "        [0.823064  ],\n",
      "        [0.21249142],\n",
      "        [0.10184143],\n",
      "        [0.61813612],\n",
      "        [0.12169939],\n",
      "        [0.05590889],\n",
      "        [0.65817527],\n",
      "        [0.00217583],\n",
      "        [0.43730831],\n",
      "        [0.3396822 ],\n",
      "        [0.88589156],\n",
      "        [0.6603234 ],\n",
      "        [0.84156947],\n",
      "        [0.66656747]],\n",
      "\n",
      "       [[0.24032674],\n",
      "        [0.43695114],\n",
      "        [0.79228727],\n",
      "        [0.28825894],\n",
      "        [0.70157259],\n",
      "        [0.47556034],\n",
      "        [0.84964748],\n",
      "        [0.17282311],\n",
      "        [0.14629587],\n",
      "        [0.91912081],\n",
      "        [0.42609606],\n",
      "        [0.68547068],\n",
      "        [0.10378526],\n",
      "        [0.76323926],\n",
      "        [0.18776732],\n",
      "        [0.66517507],\n",
      "        [0.32922433],\n",
      "        [0.67885316],\n",
      "        [0.96696984],\n",
      "        [0.01766892],\n",
      "        [0.53180295],\n",
      "        [0.21028627],\n",
      "        [0.08409837],\n",
      "        [0.47714933],\n",
      "        [0.87772393],\n",
      "        [0.4434407 ],\n",
      "        [0.36457062],\n",
      "        [0.6961336 ],\n",
      "        [0.55752443],\n",
      "        [0.91172177],\n",
      "        [0.34757206],\n",
      "        [0.43184198]],\n",
      "\n",
      "       [[0.7718958 ],\n",
      "        [0.8718299 ],\n",
      "        [0.51963474],\n",
      "        [0.23776447],\n",
      "        [0.35274097],\n",
      "        [0.04496065],\n",
      "        [0.48995815],\n",
      "        [0.19195742],\n",
      "        [0.58761515],\n",
      "        [0.27019664],\n",
      "        [0.3101439 ],\n",
      "        [0.55191748],\n",
      "        [0.68986307],\n",
      "        [0.63354182],\n",
      "        [0.75023096],\n",
      "        [0.45015188],\n",
      "        [0.17576925],\n",
      "        [0.23385343],\n",
      "        [0.46080105],\n",
      "        [0.84642493],\n",
      "        [0.99445724],\n",
      "        [0.25935999],\n",
      "        [0.30168399],\n",
      "        [0.91673555],\n",
      "        [0.9359693 ],\n",
      "        [0.55139665],\n",
      "        [0.00550544],\n",
      "        [0.0344661 ],\n",
      "        [0.97106545],\n",
      "        [0.3056664 ],\n",
      "        [0.50795084],\n",
      "        [0.46729232]],\n",
      "\n",
      "       [[0.44165913],\n",
      "        [0.70820406],\n",
      "        [0.33101429],\n",
      "        [0.68529404],\n",
      "        [0.78494655],\n",
      "        [0.62321944],\n",
      "        [0.22278574],\n",
      "        [0.62700871],\n",
      "        [0.01674255],\n",
      "        [0.26192345],\n",
      "        [0.5990458 ],\n",
      "        [0.93592634],\n",
      "        [0.27425754],\n",
      "        [0.6945223 ],\n",
      "        [0.69021575],\n",
      "        [0.71704491],\n",
      "        [0.92619001],\n",
      "        [0.31409164],\n",
      "        [0.52476534],\n",
      "        [0.13178551],\n",
      "        [0.21838897],\n",
      "        [0.59891429],\n",
      "        [0.51659739],\n",
      "        [0.93862595],\n",
      "        [0.63512566],\n",
      "        [0.41760071],\n",
      "        [0.70548967],\n",
      "        [0.9730768 ],\n",
      "        [0.88259117],\n",
      "        [0.95044927],\n",
      "        [0.70944005],\n",
      "        [0.26381837]],\n",
      "\n",
      "       [[0.68675893],\n",
      "        [0.55681391],\n",
      "        [0.6259185 ],\n",
      "        [0.65227739],\n",
      "        [0.51025619],\n",
      "        [0.89580788],\n",
      "        [0.05576177],\n",
      "        [0.97614958],\n",
      "        [0.02965864],\n",
      "        [0.51961077],\n",
      "        [0.05512912],\n",
      "        [0.27529161],\n",
      "        [0.74743244],\n",
      "        [0.21317024],\n",
      "        [0.72622531],\n",
      "        [0.85518425],\n",
      "        [0.43267533],\n",
      "        [0.77941548],\n",
      "        [0.64310295],\n",
      "        [0.9735165 ],\n",
      "        [0.44812213],\n",
      "        [0.51285389],\n",
      "        [0.09764763],\n",
      "        [0.55672793],\n",
      "        [0.41846938],\n",
      "        [0.82765004],\n",
      "        [0.96591333],\n",
      "        [0.07438332],\n",
      "        [0.54639297],\n",
      "        [0.18573948],\n",
      "        [0.16569813],\n",
      "        [0.15000523]],\n",
      "\n",
      "       [[0.16478202],\n",
      "        [0.16439384],\n",
      "        [0.57981662],\n",
      "        [0.27846354],\n",
      "        [0.75646745],\n",
      "        [0.96746262],\n",
      "        [0.36069683],\n",
      "        [0.02813042],\n",
      "        [0.29219402],\n",
      "        [0.94883475],\n",
      "        [0.81116623],\n",
      "        [0.00871009],\n",
      "        [0.05951741],\n",
      "        [0.03647283],\n",
      "        [0.73804131],\n",
      "        [0.83311935],\n",
      "        [0.9514004 ],\n",
      "        [0.22668437],\n",
      "        [0.3012742 ],\n",
      "        [0.60912721],\n",
      "        [0.17479307],\n",
      "        [0.48053689],\n",
      "        [0.03770247],\n",
      "        [0.83994447],\n",
      "        [0.51709736],\n",
      "        [0.11817616],\n",
      "        [0.19021804],\n",
      "        [0.16613644],\n",
      "        [0.18864742],\n",
      "        [0.63107913],\n",
      "        [0.32729687],\n",
      "        [0.94508503]],\n",
      "\n",
      "       [[0.45247742],\n",
      "        [0.52967779],\n",
      "        [0.78242471],\n",
      "        [0.32519738],\n",
      "        [0.53774545],\n",
      "        [0.67016981],\n",
      "        [0.92872104],\n",
      "        [0.50157329],\n",
      "        [0.54048988],\n",
      "        [0.52587107],\n",
      "        [0.29157083],\n",
      "        [0.13780819],\n",
      "        [0.99260397],\n",
      "        [0.26641335],\n",
      "        [0.72633542],\n",
      "        [0.34300959],\n",
      "        [0.00801982],\n",
      "        [0.24280761],\n",
      "        [0.46921471],\n",
      "        [0.55112368],\n",
      "        [0.75365503],\n",
      "        [0.70606357],\n",
      "        [0.88327498],\n",
      "        [0.17474652],\n",
      "        [0.8105596 ],\n",
      "        [0.88910555],\n",
      "        [0.11354102],\n",
      "        [0.75036111],\n",
      "        [0.79873197],\n",
      "        [0.36990048],\n",
      "        [0.31389791],\n",
      "        [0.06899799]],\n",
      "\n",
      "       [[0.94149773],\n",
      "        [0.9045997 ],\n",
      "        [0.68196385],\n",
      "        [0.88243726],\n",
      "        [0.73622134],\n",
      "        [0.0448414 ],\n",
      "        [0.56008793],\n",
      "        [0.01917757],\n",
      "        [0.05043661],\n",
      "        [0.494574  ],\n",
      "        [0.62048265],\n",
      "        [0.22224793],\n",
      "        [0.7379109 ],\n",
      "        [0.55396902],\n",
      "        [0.82708081],\n",
      "        [0.809873  ],\n",
      "        [0.31703615],\n",
      "        [0.70885932],\n",
      "        [0.03374566],\n",
      "        [0.59737358],\n",
      "        [0.35530368],\n",
      "        [0.16273401],\n",
      "        [0.8118951 ],\n",
      "        [0.19701725],\n",
      "        [0.25659418],\n",
      "        [0.92189054],\n",
      "        [0.83499693],\n",
      "        [0.10067763],\n",
      "        [0.25765212],\n",
      "        [0.83608937],\n",
      "        [0.33131239],\n",
      "        [0.08591809]]]), 'epoch_counter': 0}\n",
      "data: <class 'tuple'>, X: <class 'tensorflow.python.framework.ops.Tensor'> (None, None), y: <class 'tensorflow.python.framework.ops.Tensor'> (None, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/20 [>.............................] - ETA: 5s - loss: 0.4883 - mae: 0.5946iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "17/20 [========================>.....] - ETA: 0s - loss: 0.3595 - mae: 0.4925iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBDDCEB0>\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3505 - mae: 0.4825\n",
      "[BG] updated self.epoch_counter: 1\n",
      "Epoch 2/5\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      " 1/20 [>.............................] - ETA: 0s - loss: 0.2413 - mae: 0.4054iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "16/20 [=======================>......] - ETA: 0s - loss: 0.2476 - mae: 0.3993iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCED19A0>\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2558 - mae: 0.4063\n",
      "[BG] updated self.epoch_counter: 2\n",
      "Epoch 3/5\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      " 1/20 [>.............................] - ETA: 0s - loss: 0.2240 - mae: 0.3745iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "17/20 [========================>.....] - ETA: 0s - loss: 0.2018 - mae: 0.3601iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBE0C5DF0>\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2104 - mae: 0.3672\n",
      "[BG] updated self.epoch_counter: 3\n",
      "Epoch 4/5\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      " 1/20 [>.............................] - ETA: 0s - loss: 0.1875 - mae: 0.3472iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "15/20 [=====================>........] - ETA: 0s - loss: 0.1920 - mae: 0.3521iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBBE666A0>\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1937 - mae: 0.3541\n",
      "[BG] updated self.epoch_counter: 4\n",
      "Epoch 5/5\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      " 1/20 [>.............................] - ETA: 0s - loss: 0.1507 - mae: 0.3270iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "18/20 [==========================>...] - ETA: 0s - loss: 0.1923 - mae: 0.3530iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "iterator: <tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x000001EEBCF661C0>\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1876 - mae: 0.3487\n",
      "[BG] updated self.epoch_counter: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eebced1250>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "\n",
    "def _disallow_inside_tf_function(method_name):\n",
    "    if tf.inside_function():\n",
    "        error_msg = (\n",
    "                'Detected a call to `Model.{method_name}` inside a `tf.function`. '\n",
    "                '`Model.{method_name} is a high-level endpoint that manages its own '\n",
    "                '`tf.function`. Please move the call to `Model.{method_name}` outside '\n",
    "                'of all enclosing `tf.function`s. Note that you can call a `Model` '\n",
    "                'directly on `Tensor`s inside a `tf.function` like: `model(x)`.'\n",
    "        ).format(method_name=method_name)\n",
    "        raise RuntimeError(error_msg)\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    \n",
    "    def _disallow_inside_tf_function(method_name):\n",
    "        if tf.inside_function():\n",
    "            error_msg = (\n",
    "                    'Detected a call to `Model.{method_name}` inside a `tf.function`. '\n",
    "                    '`Model.{method_name} is a high-level endpoint that manages its own '\n",
    "                    '`tf.function`. Please move the call to `Model.{method_name}` outside '\n",
    "                    'of all enclosing `tf.function`s. Note that you can call a `Model` '\n",
    "                    'directly on `Tensor`s inside a `tf.function` like: `model(x)`.'\n",
    "            ).format(method_name=method_name)\n",
    "            raise RuntimeError(error_msg)\n",
    "    \n",
    "    @traceback_utils.filter_traceback\n",
    "    def fit(self,\n",
    "            x=None,\n",
    "            y=None,\n",
    "            batch_size=None,\n",
    "            epochs=1,\n",
    "            verbose='auto',\n",
    "            callbacks=None,\n",
    "            validation_split=0.,\n",
    "            validation_data=None,\n",
    "            shuffle=True,\n",
    "            class_weight=None,\n",
    "            sample_weight=None,\n",
    "            initial_epoch=0,\n",
    "            steps_per_epoch=None,\n",
    "            validation_steps=None,\n",
    "            validation_batch_size=None,\n",
    "            validation_freq=1,\n",
    "            max_queue_size=10,\n",
    "            workers=1,\n",
    "            use_multiprocessing=False):\n",
    "      \n",
    "        base_layer.keras_api_gauge.get_cell('fit').set(True)\n",
    "        # Legacy graph support is contained in `training_v1.Model`.\n",
    "        version_utils.disallow_legacy_graph('Model', 'fit')\n",
    "        self._assert_compile_was_called()\n",
    "        self._check_call_args('fit')\n",
    "        _disallow_inside_tf_function('fit')\n",
    "        if verbose == 'auto':\n",
    "            if self.distribute_strategy._should_use_with_coordinator:        # pylint: disable=protected-access\n",
    "                        verbose = 2        # Default to epoch-level logging for PSStrategy.\n",
    "            else:\n",
    "                        verbose = 1        # Default to batch-level logging otherwise.\n",
    "        elif verbose == 1 and self.distribute_strategy._should_use_with_coordinator:        # pylint: disable=protected-access\n",
    "            raise ValueError(\n",
    "                                    '`verbose=1` is not allowed with `ParameterServerStrategy` for '\n",
    "                                    f'performance reasons. Received: `verbose`={verbose}')\n",
    "        if validation_split:\n",
    "                    # Create the validation data using the training data. Only supported for\n",
    "                    # `Tensor` and `NumPy` input.\n",
    "                    (x, y, sample_weight), validation_data = (\n",
    "                                    data_adapter.train_validation_split(\n",
    "                                                    (x, y, sample_weight), validation_split=validation_split))\n",
    "        if validation_data:\n",
    "            val_x, val_y, val_sample_weight = (\n",
    "                    data_adapter.unpack_x_y_sample_weight(validation_data))\n",
    "        if self.distribute_strategy._should_use_with_coordinator:    # pylint: disable=protected-access\n",
    "            self._cluster_coordinator = tf.distribute.experimental.coordinator.ClusterCoordinator(\n",
    "                    self.distribute_strategy)\n",
    "        with self.distribute_strategy.scope(), \\\n",
    "                 training_utils.RespectCompiledTrainableState(self):\n",
    "            # Creates a `tf.data.Dataset` and handles batch and epoch iteration.\n",
    "            data_handler = data_adapter.get_data_handler(\n",
    "                    x=x,\n",
    "                    y=y,\n",
    "                    sample_weight=sample_weight,\n",
    "                    batch_size=batch_size,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    initial_epoch=initial_epoch,\n",
    "                    epochs=epochs,\n",
    "                    shuffle=shuffle,\n",
    "                    class_weight=class_weight,\n",
    "                    max_queue_size=max_queue_size,\n",
    "                    workers=workers,\n",
    "                    use_multiprocessing=use_multiprocessing,\n",
    "                    model=self,\n",
    "                    steps_per_execution=self._steps_per_execution)\n",
    "            self.data_handler = data_handler\n",
    "            # Container that configures and calls `tf.keras.Callback`s.\n",
    "            if not isinstance(callbacks, callbacks_module.CallbackList):\n",
    "                callbacks = callbacks_module.CallbackList(\n",
    "                        callbacks,\n",
    "                        add_history=True,\n",
    "                        add_progbar=verbose != 0,\n",
    "                        model=self,\n",
    "                        verbose=verbose,\n",
    "                        epochs=epochs,\n",
    "                        steps=data_handler.inferred_steps)\n",
    "            self.stop_training = False\n",
    "            self.train_function = self.make_train_function()\n",
    "            self._train_counter.assign(0)\n",
    "            callbacks.on_train_begin()\n",
    "            training_logs = None\n",
    "            # Handle fault-tolerance for multi-worker.\n",
    "            # TODO(omalleyt): Fix the ordering issues that mean this has to\n",
    "            # happen after `callbacks.on_train_begin`.\n",
    "            data_handler._initial_epoch = (    # pylint: disable=protected-access\n",
    "                    self._maybe_load_initial_epoch_from_ckpt(initial_epoch))\n",
    "            logs = None\n",
    "            \n",
    "            print(vars(data_handler))\n",
    "            \n",
    "            for epoch, iterator in data_handler.enumerate_epochs():\n",
    "                self.reset_metrics()\n",
    "                callbacks.on_epoch_begin(epoch)\n",
    "                with data_handler.catch_stop_iteration():\n",
    "                    for step in data_handler.steps():\n",
    "                        with tf.profiler.experimental.Trace(\n",
    "                                'train',\n",
    "                                epoch_num=epoch,\n",
    "                                step_num=step,\n",
    "                                batch_size=batch_size,\n",
    "                                _r=1):\n",
    "                            callbacks.on_train_batch_begin(step)\n",
    "                            print(f'iterator: {iterator}')\n",
    "                            tmp_logs = self.train_function(iterator)\n",
    "                            if data_handler.should_sync:\n",
    "                                context.async_wait()\n",
    "                            logs = tmp_logs    # No error, now safe to assign to logs.\n",
    "                            end_step = step + data_handler.step_increment\n",
    "                            callbacks.on_train_batch_end(end_step, logs)\n",
    "                            if self.stop_training:\n",
    "                                break\n",
    "                \n",
    "                logs = tf_utils.sync_to_numpy_or_python_type(logs)\n",
    "                if logs is None:\n",
    "                    raise ValueError('Unexpected result of `train_function` '\n",
    "                                                     '(Empty logs). Please use '\n",
    "                                                     '`Model.compile(..., run_eagerly=True)`, or '\n",
    "                                                     '`tf.config.run_functions_eagerly(True)` for more '\n",
    "                                                     'information of where went wrong, or file a '\n",
    "                                                     'issue/bug to `tf.keras`.')\n",
    "                epoch_logs = copy.copy(logs)\n",
    "                # Run validation.\n",
    "                if validation_data and self._should_eval(epoch, validation_freq):\n",
    "                    # Create data_handler for evaluation and cache it.\n",
    "                    if getattr(self, '_eval_data_handler', None) is None:\n",
    "                        self._eval_data_handler = data_adapter.get_data_handler(\n",
    "                                x=val_x,\n",
    "                                y=val_y,\n",
    "                                sample_weight=val_sample_weight,\n",
    "                                batch_size=validation_batch_size or batch_size,\n",
    "                                steps_per_epoch=validation_steps,\n",
    "                                initial_epoch=0,\n",
    "                                epochs=1,\n",
    "                                max_queue_size=max_queue_size,\n",
    "                                workers=workers,\n",
    "                                use_multiprocessing=use_multiprocessing,\n",
    "                                model=self,\n",
    "                                steps_per_execution=self._steps_per_execution)\n",
    "                    val_logs = self.evaluate(\n",
    "                            x=val_x,\n",
    "                            y=val_y,\n",
    "                            sample_weight=val_sample_weight,\n",
    "                            batch_size=validation_batch_size or batch_size,\n",
    "                            steps=validation_steps,\n",
    "                            callbacks=callbacks,\n",
    "                            max_queue_size=max_queue_size,\n",
    "                            workers=workers,\n",
    "                            use_multiprocessing=use_multiprocessing,\n",
    "                            return_dict=True,\n",
    "                            _use_cached_eval_dataset=True)\n",
    "                    val_logs = {'val_' + name: val for name, val in val_logs.items()}\n",
    "                    epoch_logs.update(val_logs)\n",
    "                callbacks.on_epoch_end(epoch, epoch_logs)\n",
    "                training_logs = epoch_logs\n",
    "                if self.stop_training:\n",
    "                    break\n",
    "            # If eval data_handler exists, delete it after all epochs are done.\n",
    "            if getattr(self, '_eval_data_handler', None) is not None:\n",
    "                del self._eval_data_handler\n",
    "            callbacks.on_train_end(logs=training_logs)\n",
    "            return self.history\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        print(vars(self.data_handler._adapter._keras_sequence))\n",
    "        x, y = data\n",
    "        print(f'data: {type(data)}, X: {type(x)} {x.shape}, y: {type(y)} {y.shape}')\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute our own loss\n",
    "            loss = keras.losses.mean_squared_error(y, y_pred)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Compute our own metrics\n",
    "        loss_tracker.update_state(loss)\n",
    "        mae_metric.update_state(y, y_pred)\n",
    "        return {\"loss\": loss_tracker.result(), \"mae\": mae_metric.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        return [loss_tracker, mae_metric]\n",
    "\n",
    "\n",
    "# Construct an instance of CustomModel\n",
    "inputs = keras.Input(shape=(14,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "# We don't passs a loss or metrics here.\n",
    "model.compile(optimizer=\"adam\")\n",
    "\n",
    "# Just use `fit` as usual -- you can use callbacks, etc.\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "model.fit(batch_generator, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
